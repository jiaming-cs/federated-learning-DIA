2021-11-12 15:18:51.564799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:18:51.564846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.244269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.244319: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.254918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.254966: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.260375: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.260373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.260415: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.260420: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.267753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.267800: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.284017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.284064: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.291075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.291120: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.307668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.307714: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.313123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.313166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.313346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.313398: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.341638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.341687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.369665: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.369710: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.410903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.410949: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.427331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.427376: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.427563: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.427598: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.484771: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.484815: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.573214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.573257: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.576223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.576262: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.622914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.622959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:17.623290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-12 15:19:17.623322: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-12 15:19:21.991823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:21.991887: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:21.991913: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:21.992272: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.161475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.161534: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.161560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.161834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.242139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.242191: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.242216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.242475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.278939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.278993: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.279027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.279308: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.294323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.294376: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.294401: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.294667: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.317334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.317388: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.317419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.317710: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.329851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.329899: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.329925: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.330191: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.375575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.375625: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.375651: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.375915: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.414463: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.414519: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.414547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.414641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.414683: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.414705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.414823: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.414972: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.437278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.437324: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.437349: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.437611: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.447003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.447053: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.447078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.447341: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.463086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.463139: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.463164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.463419: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.472221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.472270: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.472295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.472590: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.497335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.497386: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.497413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.497690: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.505986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.506032: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.506055: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.506305: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.520524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.520578: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.520603: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.520861: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.552212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.552268: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.552295: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.552561: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.717919: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.717968: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.718004: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.718263: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-12 15:19:22.815916: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-12 15:19:22.815983: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-12 15:19:22.816013: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-12 15:19:22.816264: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-12 15:19:41,419 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:19:41,431 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:19:41,491 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:19:42,580 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:19:42,588 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:19:42,631 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:01,360 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:01,364 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-12 15:21:01,415 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:01,439 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:01,613 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:01,613 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:01,667 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:03,023 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:03,024 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:03,091 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-12 15:21:10,623 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:10,647 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:10,647 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:11,299 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:11,300 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:11,343 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:11,652 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:11,655 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-12 15:21:11,659 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:11,684 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:15,890 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:15,890 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:15,914 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:16,348 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:16,348 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-12 15:21:16,351 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:16,365 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:17,947 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:17,967 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-12 15:21:17,999 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:18,055 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:18,932 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:18,933 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-12 15:21:18,933 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:18,954 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:20,468 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:20,468 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-12 15:21:20,503 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:20,545 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:22,792 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:22,793 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:22,810 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:22,842 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:22,856 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:22,876 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-12 15:21:23,434 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:23,438 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:23,439 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:23,888 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:23,888 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-12 15:21:23,893 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-12 15:21:23,953 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:23,954 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:23,959 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:24,445 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-12 15:21:24,446 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:24,450 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:21:26,577 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:21:26,580 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-12 15:21:26,581 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-12 15:21:26,583 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-12 15:24:12,641 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,641 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,640 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,641 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,641 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,640 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,641 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-12 15:24:12,991 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,992 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:12,993 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,081 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,081 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-12 15:24:13,082 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607241455","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607241471","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607584967","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607602183","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607247940","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607618881","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607241787","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607605083","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607243147","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607604971","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607259316","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607700628","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607581530","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607599084","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607665851","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607713598","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607241789","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607243092","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607548662","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("[::]:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1636730651.607691990","description":"Error received from peer ipv6:[::]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
[1762 2180 1657 ... 1024 1986  339]
create data 0
[2125 1239 2347 ...  383  618 1417]
create data 1
[1968 1718 2198 ... 1231  345 2203]
create data 2
[  83 1165  170 ... 1105 2255 2008]
create data 3
[ 326 1790  203 ...  451  200  422]
create data 4
[ 443 2402 1613 ...  105 1561 1569]
create data 5
[1528 2277 2104 ... 2142 1848 2398]
create data 6
[2407 2309 1863 ... 2151  137 2124]
create data 7
[1814 2243 2496 ... 2012 2251 1735]
create data 8
[1280 1588  638 ... 1949  877  455]
create data 9
[1262  853 1545 ...  737 1363  273]
create data 10
[2386  674 1856 ...  193  944 2409]
create data 11
[1136 2007  960 ...  467  272 1104]
create data 12
[ 147 1542 1780 ... 1066 2051 2001]
create data 13
[2474  222  860 ... 2195 1614 1005]
create data 14
[ 849 1442 1467 ... 1065 1428  605]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_19_fault_15.log
Traceback (most recent call last):
  File "/home/flresearchksu/federated-learning-DIA/cloud/cifar/main.py", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
2021-11-19 05:04:33.915179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:33.927055: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.142497: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.142546: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.148543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.148600: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.184848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.184897: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.192213: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.192266: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.193958: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.193994: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.239723: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.239775: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.276835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.276881: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.297768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.297813: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.299707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.299742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:04:59.480566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:04:59.480615: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:05:01.252176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.252231: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.252271: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.252567: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.530808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.530861: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.530886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.531178: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.550849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.550905: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.550933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.551242: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.576934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.576987: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.577011: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.577282: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.624448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.624499: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.624526: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.624827: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.689623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.689671: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.689707: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.689977: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.703333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.703386: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.703412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.703737: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.785044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.785099: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.785121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.785388: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:01.833720: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:01.833786: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:01.833813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:01.834089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:05:02.112925: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:05:02.112987: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:05:02.113015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:05:02.113275: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:20.779931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:20.779973: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.330773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.330825: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.348625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.348674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.374118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.374168: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.389135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.389185: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.418732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.418780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.428528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.428577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.431103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.431139: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.433528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.433561: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.438663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.438696: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.451706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.451765: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.480948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.480995: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.494539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.494586: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.520683: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.520732: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.532883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.532929: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.538041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.538081: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.619021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.619069: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.679442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.679485: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.680065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.680100: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.692407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.692452: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:46.741387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 05:08:46.741433: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 05:08:51.201282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.201335: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.201359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.201684: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.266099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.287602: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.287661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.288056: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.331160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.331210: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.331233: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.331494: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.335075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.335112: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.335136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.335399: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.339645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.339680: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.339701: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.339956: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.343417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.343448: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.343468: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.343762: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.386548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.386604: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.386630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.386912: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.402267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.402318: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.402343: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.402609: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.433910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.433965: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.433990: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.434263: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.451214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.451282: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.451306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.467664: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.473038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.473090: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.473115: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.473416: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.483794: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.483840: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.483865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.484125: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.512122: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.512175: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.512201: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.512493: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.545285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.545335: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.545360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.545647: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.572979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.573035: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.573060: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.573327: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.573802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.573836: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.573858: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.574117: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.576527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.576565: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.576586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.576861: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.705864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.705920: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.705945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.706193: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.726634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.726697: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.726723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.726983: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 05:08:51.812492: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 05:08:51.812552: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 05:08:51.812580: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 05:08:51.812845: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 05:09:15,307 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:09:15,312 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:09:15,371 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:09:16,108 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:09:16,112 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 05:09:16,139 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:09:16,407 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:29,403 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:29,411 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:29,455 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:30,480 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:30,480 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 05:10:30,645 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:30,739 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:31,075 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:31,076 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 05:10:31,111 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:31,120 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:32,239 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:32,243 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 05:10:32,263 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:32,307 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:37,771 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:37,772 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:37,826 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:41,054 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:41,054 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 05:10:41,055 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:41,156 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:41,253 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:41,258 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:41,277 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:42,975 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:42,979 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:43,091 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:44,779 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:44,780 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:44,780 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:44,943 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:44,967 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:45,007 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:45,324 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:45,325 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:45,359 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:46,191 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:46,192 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 05:10:46,193 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:46,227 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:46,242 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:46,242 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:46,242 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 05:10:47,090 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:47,147 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:47,148 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:47,475 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:47,548 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 05:10:47,573 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:47,600 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:50,783 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:50,783 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 05:10:50,837 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:50,914 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 05:10:50,972 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:50,995 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 05:10:50,999 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 05:10:51,801 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-19 05:10:51,818 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 05:10:51,821 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 05:10:51,834 | connection.py:36 | ChannelConnectivity.READY
Segmentation fault
[1665  959 2444 ... 1683 1911 1071]
create data 0
[1986 1215 2156 ... 2441   15  364]
create data 1
[1945 2302 1311 ... 2044 2032  575]
create data 2
[1436 1907 1296 ...  628  675  957]
create data 3
[1646 2206 2213 ... 1473  746 1530]
create data 4
[  30 2146 1224 ... 2263 2198  710]
create data 5
[ 819 2263 1192 ...  236 1377 1551]
create data 6
[ 741 2193  612 ...  194 2134 1441]
create data 7
[ 383 1262 1133 ... 1497  843  580]
create data 8
[1345 1441 1416 ... 1715 1624  530]
create data 9
[2494   41  224 ... 1493 1159  919]
create data 10
[ 945   15 2476 ...  526  542 2164]
create data 11
[ 338 2056 1354 ...  771  586 1368]
create data 12
[1113   69  862 ...  513  924 1011]
create data 13
[1432  390 1664 ...   45  838 1192]
create data 14
[1353  779 1611 ...  215 2498 1761]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs/20_16_attack_0.8_kmeans/client_19_fault_15.log
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 05:26:38,001 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,001 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,002 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 05:26:38,002 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,003 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,003 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 05:26:38,003 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 05:26:38,005 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 05:26:38,005 | app.py:72 | Disconnect and shut down
2021-11-19 14:20:22.918711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:22.918754: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.459305: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.459358: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.460984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.461020: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.463504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.463561: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.466912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.466942: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.477376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.477414: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.483513: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.483573: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.486249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.486281: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.520070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.520125: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.540204: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.540270: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.558155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.558203: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.563337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.563379: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.564452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.564485: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.567541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.567574: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.575928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.575964: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.588524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.588570: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.630591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.630637: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.676483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.676549: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.682946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.682993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.690859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.690901: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:52.697039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 14:20:52.697086: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 14:20:57.360082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.360144: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.360171: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.360469: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.385331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.385385: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.385410: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.385720: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.390984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.391026: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.391049: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.391301: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.398503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.398559: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.398583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.398847: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.434210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.434267: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.434293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.434566: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.462831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.462890: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.462920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.463202: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.473746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.473799: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.473823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.474086: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.479369: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.479415: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.479441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.479757: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.514881: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.514937: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.514962: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.515241: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.520569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.520611: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.520636: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.520941: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.524574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.524611: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.524634: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.524914: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.559449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.559501: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.559539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.571228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.571283: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.571309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.577972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.578022: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.578047: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.578321: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.579782: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.595648: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.647405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.647456: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.647481: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.647777: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.714969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.715027: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.715064: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.715317: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.854772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.854836: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.854867: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.855147: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:57.907883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:57.907931: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:57.907955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:57.908212: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:58.021161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:58.021212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:58.021236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:58.021498: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 14:20:58.056674: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 14:20:58.056724: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 14:20:58.056749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 14:20:58.056999: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 14:21:12,831 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:12,839 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 14:21:12,852 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:12,865 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,083 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,084 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,103 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,111 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,111 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,119 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,159 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,160 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,183 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,250 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,251 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,251 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,351 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,357 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,358 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,359 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,360 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,361 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,361 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 14:21:13,362 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,362 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,358 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,366 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,366 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,368 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 14:21:13,367 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 14:21:13,375 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,377 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,383 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,383 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 14:21:13,391 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,406 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,410 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,410 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,411 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,412 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,412 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,412 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,416 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,417 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,417 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,417 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,418 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,418 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,419 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,419 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,419 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 14:21:13,420 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,420 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 14:21:13,425 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,425 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,426 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,426 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,431 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,431 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,432 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,432 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,450 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,450 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,450 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,451 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 14:21:13,461 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 14:21:13,462 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 14:21:13,462 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 14:21:13,462 | app.py:61 | Opened (insecure) gRPC connection
2021-11-19 14:28:24.162793: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_grad_filter_ops.cc:547 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[101,169,288] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
DEBUG flower 2021-11-19 14:28:33,774 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 66, in start_client
    client, server_message
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 40, in handle
    return _fit(client, server_msg.fit_ins), 0, True
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 57, in _fit
    fit_res = client.fit(fit_ins)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/numpy_client.py", line 192, in fit
    results = self.numpy_client.fit(parameters, ins.config)
  File "client.py", line 117, in fit
    h = model.fit(x_train, y_train, epochs=5, batch_size=128)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[101,169,288] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[node gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilter
 (defined at /home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:464)
]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_3843]

Errors may have originated from an input operation.
Input Source operations connected to node gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropFilter:
In[0] model/max_pooling2d/MaxPool (defined at /home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/layers/pooling.py:362)	
In[1] gradient_tape/model/conv2d_4/Conv2D/ShapeN:	
In[2] gradient_tape/model/conv2d_4/ReluGrad:

Operation defined at: (most recent call last)
>>>   File "client.py", line 143, in <module>
>>>     fl.client.start_numpy_client("localhost:8080", client=CifarClient())
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
>>>     grpc_max_message_length=grpc_max_message_length,
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 66, in start_client
>>>     client, server_message
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 40, in handle
>>>     return _fit(client, server_msg.fit_ins), 0, True
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 57, in _fit
>>>     fit_res = client.fit(fit_ins)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/numpy_client.py", line 192, in fit
>>>     results = self.numpy_client.fit(parameters, ins.config)
>>> 
>>>   File "client.py", line 117, in fit
>>>     h = model.fit(x_train, y_train, epochs=5, batch_size=128)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 64, in error_handler
>>>     return fn(*args, **kwargs)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 1216, in fit
>>>     tmp_logs = self.train_function(iterator)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 878, in train_function
>>>     return step_function(self, iterator)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 867, in step_function
>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 860, in run_step
>>>     outputs = model.train_step(data)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 816, in train_step
>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 531, in minimize
>>>     loss, var_list=var_list, grad_loss=grad_loss, tape=tape)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 583, in _compute_gradients
>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 464, in _get_gradients
>>>     grads = tape.gradient(loss, var_list, grad_loss)
>>> 
2021-11-19 15:28:58.730098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:28:58.733654: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.574779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.574832: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.599069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.599118: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.614313: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.614362: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.624062: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.624126: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.629722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.629771: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.632011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.632049: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.639729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.639772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.640100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.640131: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.675675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.675724: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.683499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.683561: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.686335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.686371: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.699504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.699565: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.729793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.729843: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.732653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.732688: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.733104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.733135: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.739324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.739359: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.786251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.786299: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.827897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.827942: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.863035: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.863079: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:26.879304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 15:29:26.879352: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 15:29:31.474677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.474731: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.474756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.475037: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.514242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.514304: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.514334: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.514637: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.556224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.556281: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.556306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.556629: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.579243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.579300: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.579327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.583210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.583251: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.583276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.583559: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.587652: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.618980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.619034: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.619059: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.619334: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.626827: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.626881: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.626909: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.627224: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.632380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.632422: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.632446: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.632725: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.637064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.637114: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.637139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.637413: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.667200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.667260: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.667288: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.675703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.697364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.697415: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.697441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.697709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.704698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.704757: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.704782: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.705063: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.705104: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.705145: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.705168: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.705432: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.736336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.736393: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.736419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.736709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.745768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.745828: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.745856: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.746142: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.791249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.791307: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.791333: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.791632: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.816850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.816905: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.816930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.817185: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.841828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.841882: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.841907: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.842197: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.946099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.946162: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.946188: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.946457: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 15:29:31.987340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 15:29:31.987393: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 15:29:31.987419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 15:29:31.995759: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 15:29:38,015 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,016 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,017 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,019 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,019 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 15:29:38,027 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,035 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,051 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,055 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,056 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,056 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,056 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,061 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,067 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,068 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 15:29:38,073 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,075 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,079 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,080 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,091 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,094 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,094 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,095 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,111 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,114 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,115 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,115 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,116 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,116 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,125 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,125 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,131 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,143 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,145 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,146 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,147 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,146 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,148 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,149 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,149 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,149 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,148 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,149 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,149 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,149 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,150 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,149 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 15:29:38,151 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 15:29:38,151 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,151 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,173 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,174 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,174 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,175 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,205 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,206 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,206 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 15:29:38,206 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,206 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,206 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 15:29:38,206 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 15:29:38,207 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 15:29:38,210 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 15:29:38,211 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 15:29:38,211 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 15:29:38,211 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
[ 448 1184 1758 ...  834 1640  361]
create data 0
[1235 1203 2055 ...  662  839  465]
create data 1
[ 544 1162 2140 ... 1485 2424 2317]
create data 2
[ 895 2336  980 ...  736  490 2040]
create data 3
[1844 2005  994 ...  111  510 2345]
create data 4
[2236  498 2299 ... 2464  445 1149]
create data 5
[ 522  564  557 ... 1034 1984  206]
create data 6
[2324 1265 1376 ... 1667 1939  353]
create data 7
[1883 2123 1139 ...  552 1352 1254]
create data 8
[1096 2168 1401 ...  338 2217  623]
create data 9
[2146 2262 2109 ...  522  210 1421]
create data 10
[ 446 2003 1841 ...  286 1413 1060]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_19_fault_11.log
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:00:14,050 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:00:14,051 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:00:14,052 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:00:14,053 | app.py:72 | Disconnect and shut down
2021-11-19 16:24:15.629871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:15.629920: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.622583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.622639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.677546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.677612: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.698739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.698786: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.700733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.700773: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.707073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.707110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.739615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.739677: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.757362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.757407: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.798902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.798950: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.814903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.814951: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.817167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.817200: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.826441: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.826481: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.866748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.866793: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.878230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.878273: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.917185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.917233: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.919775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.919814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.933270: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.933312: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.935318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.935352: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:44.983163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:44.983209: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:45.000619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:45.000665: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:45.012857: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 16:24:45.012901: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 16:24:49.477846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.477903: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.477928: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.478215: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.554861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.554923: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.554952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.555239: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.670148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.670201: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.670228: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.670526: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.682412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.682471: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.682499: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.682801: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.710940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.710987: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.711009: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.711262: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.718175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.718222: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.718245: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.718505: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.735311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.735360: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.735385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.739764: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.758663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.758710: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.758735: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.759016: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.822142: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.822189: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.822214: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.822475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.822788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.822828: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.822851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.823116: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.866495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.866561: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.866590: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.866863: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.874179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.874225: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.874249: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.874529: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.881881: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.881936: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.881965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.882276: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.921822: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.921874: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.921898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.922148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.948329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.948387: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.948417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.948721: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:49.986294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:49.986352: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:49.986383: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:49.986667: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:50.040429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:50.040490: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:50.040521: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:50.040815: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:50.055071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:50.055127: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:50.055154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:50.055412: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:50.081159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:50.081212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:50.081236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:50.081486: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 16:24:50.143031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 16:24:50.143089: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 16:24:50.143127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 16:24:50.143393: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 16:25:12,563 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:25:12,567 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 16:25:12,568 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:25:12,568 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:25:12,617 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 16:25:12,617 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:31,679 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:31,680 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:31,695 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:35,164 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:35,165 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:35,203 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:38,682 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:38,683 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:38,688 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:39,077 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:39,077 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 16:26:39,078 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:39,179 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 16:26:39,919 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:39,929 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:39,938 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 16:26:42,758 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:42,759 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:42,796 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 16:26:43,724 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:43,767 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:43,772 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 16:26:45,672 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:45,672 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:45,699 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:47,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:47,151 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 16:26:47,153 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:47,240 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:47,956 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:47,961 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:47,987 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:48,940 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:48,940 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 16:26:48,962 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:48,971 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:50,696 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:50,764 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:50,839 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:52,501 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:52,501 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 16:26:52,503 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:52,579 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:56,890 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:56,894 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:56,992 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:59,286 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:59,286 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 16:26:59,288 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:59,288 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:26:59,889 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:26:59,927 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:26:59,930 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 16:27:00,266 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:27:00,267 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:27:00,299 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 16:27:04,228 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 16:27:04,231 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 16:27:04,255 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 16:27:04,257 | app.py:61 | Opened (insecure) gRPC connection
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
2021-11-19 16:33:45.015969: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:42:50,777 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 16:42:50,774 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:42:50,777 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 16:42:50,778 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 16:42:50,778 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 16:42:50,778 | app.py:72 | Disconnect and shut down
[ 584 1970 1849 ...  919  764  138]
create data 0
[2327 2312 1228 ...   50 1425 1925]
create data 1
[1463 2047  858 ... 1871  351 1150]
create data 2
[  19 1269 2293 ... 1642 1056  510]
create data 3
[ 790  263 2147 ... 2124  449  491]
create data 4
[ 363 1857  965 ... 1878 1520 1378]
create data 5
[ 136  821  541 ... 2335 2453 1807]
create data 6
[  47  395 1349 ... 2463 1004  479]
create data 7
[ 552 1608 2143 ... 1967 1233  144]
create data 8
[1660 1139 1736 ...  533 2385 2128]
create data 9
[1633 2087  607 ... 2248 2343 1853]
create data 10
[1767 2374  998 ... 1298 1042 2225]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_19_fault_11.log
2021-11-19 17:17:50.252241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:17:50.252297: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.036832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.036885: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.088910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.088959: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.118353: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.118402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.123075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.123121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.131108: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.131153: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.147342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.147394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.148693: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.148727: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.170912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.170958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.192917: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.192967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.220900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.220948: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.295161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.295206: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.307221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.307267: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.307938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.307971: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.316703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.316747: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.320448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.320487: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.336105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.336148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.345952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.346001: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.353663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.353706: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.433333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.433378: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:19.477279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 17:18:19.477327: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 17:18:23.923055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:23.923126: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:23.923149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:23.923418: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:23.938443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:23.938497: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:23.938522: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:23.938798: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:23.947798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:23.947851: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:23.947874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:23.948165: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.093505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.093556: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.093581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.093852: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.119549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.119607: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.119633: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.147914: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.200163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.200213: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.200261: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.200524: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.204558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.204594: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.204614: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.204881: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.229922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.229979: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.230007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.230266: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.237818: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.237864: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.237889: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.238166: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.288805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.288859: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.288898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.289160: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.344798: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.344854: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.344878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.345130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.347077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.347107: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.347124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.347351: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.351385: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.351425: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.351447: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.351739: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.386277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.386328: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.386354: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.386617: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.398555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.398607: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.398629: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.398891: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.432445: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.432497: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.432534: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.432797: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.482717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.482768: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.482793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.483061: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.546253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.546313: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.546345: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.546656: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.602308: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.602373: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.602405: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.602715: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 17:18:24.619335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 17:18:24.619398: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 17:18:24.619429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 17:18:24.619729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 17:18:45,995 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-19 17:18:46,059 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:18:46,124 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:18:46,112 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:18:46,128 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:18:46,178 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:14,161 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:14,162 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:14,163 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:14,546 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:14,549 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:14,661 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:17,655 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:17,656 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 17:20:17,663 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:17,663 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:20:19,273 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:19,274 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:19,335 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:24,189 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:24,207 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:24,215 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:24,395 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:24,395 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:24,396 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 17:20:24,638 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:24,805 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:24,810 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:20:25,200 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:25,205 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:25,241 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 17:20:26,779 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:26,786 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:26,786 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:20:33,213 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:33,214 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 17:20:33,224 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:33,279 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:34,179 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:34,179 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 17:20:34,181 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:34,197 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:20:35,111 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:35,111 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:35,112 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:35,518 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:35,518 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 17:20:35,583 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:35,688 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 17:20:36,109 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:36,110 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:36,143 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:37,172 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:37,173 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:37,186 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:38,606 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:38,608 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:38,623 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:38,686 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:38,689 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:38,693 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 17:20:40,508 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 17:20:40,509 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 17:20:40,511 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
[2258  336 2261 ...  297 1272  684]
create data 0
[1672 1405 1689 ...  272 1855 2301]
create data 1
[ 206 2283  188 ... 2352  939 2460]
create data 2
[ 249  337   64 ... 2454 1699 1971]
create data 3
[  55  768 2064 ... 2012 1501  500]
create data 4
[2312 1972   41 ... 1459  258  982]
create data 5
[2029  209  717 ... 2385 2103 1705]
create data 6
[1314  389 2212 ... 2216 1534  221]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_19_fault_7.log
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,065 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,066 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 17:37:26,066 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 17:37:26,068 | app.py:72 | Disconnect and shut down
2021-11-19 18:20:42.633260: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:20:42.633305: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.356245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.356297: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.407126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.407176: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.428849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.428897: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.432005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.432050: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.456110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.456159: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.482662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.482720: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.487900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.487949: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.546159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.546209: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.552926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.552972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.585239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.585284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.588811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.588852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.623921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.623969: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.650235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.650283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.686422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.686470: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.686695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.686729: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.690446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.690484: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.722292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.722342: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.734495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.734551: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.785355: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.785398: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:11.812165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-19 18:21:11.812223: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-19 18:21:16.321334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.321392: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.321417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.321694: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.370793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.370845: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.370870: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.371136: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.387900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.387952: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.387978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.388324: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.413675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.413732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.413757: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.414028: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.460566: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.460618: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.460656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.460932: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.492706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.492755: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.492780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.493037: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.513628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.513679: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.513705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.514000: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.572914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.572962: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.572988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.573247: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.607931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.607989: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.608015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.608284: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.608560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.608592: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.608613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.608870: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.615182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.615227: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.615248: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.615503: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.645244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.645296: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.645320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.645597: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.661880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.661929: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.661954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.662214: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.706272: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.706323: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.706347: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.706629: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.717704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.717753: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.717777: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.718059: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.798489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.798550: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.798574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.798838: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.802784: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.802823: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.802845: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.803098: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.846656: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.846713: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.846739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.847000: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.871143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.871212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.871237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.871494: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-19 18:21:16.928428: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-19 18:21:16.928485: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-19 18:21:16.928511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-19 18:21:16.928756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-19 18:21:22,867 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,868 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,872 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,873 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:22,879 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,881 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:22,881 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,895 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,897 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:22,902 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,925 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,925 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:22,925 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,926 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,930 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,931 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:22,931 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:22,931 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 18:21:22,937 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 18:21:22,957 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,957 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,959 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:22,960 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 18:21:22,960 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,961 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,967 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,967 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,972 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,978 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,979 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,981 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,981 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:22,981 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 18:21:22,982 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-19 18:21:22,982 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,982 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,983 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,983 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:22,983 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:22,984 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-19 18:21:22,984 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:22,984 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:22,985 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,007 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,007 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,008 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,008 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,009 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,009 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,010 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,010 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,011 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,022 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,023 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:23,024 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,031 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,032 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:23,033 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,039 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,039 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,042 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,043 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:23,043 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,072 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,072 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-19 18:21:23,073 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,073 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-19 18:21:23,079 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,079 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:23,080 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:23,080 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-19 18:21:23,113 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-19 18:21:23,114 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-19 18:21:23,114 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-19 18:21:23,114 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
[ 790 1991 1063 ...  851  668 1732]
create data 0
[ 130  592 1314 ... 1499 1728  178]
create data 1
[1907 1020 1698 ... 1575 1141 2280]
create data 2
[ 881  158  966 ... 1934  884  740]
create data 3
[1538 1232 2429 ... 2337  995 1651]
create data 4
[ 790  493 1653 ... 1692  614 1659]
create data 5
[1772  233 2078 ...  109 1495 2442]
create data 6
[ 666  282  837 ... 1583  759 1860]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs/20_8_attack_0.8/client_19_fault_7.log
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-19 18:52:38,308 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-19 18:52:38,309 | app.py:72 | Disconnect and shut down
2021-11-22 17:38:52.454100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:38:52.454146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.262553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.262609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.299334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.299384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.320360: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.320413: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.322935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.322981: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.323007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.323049: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.331374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.331419: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.332636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.332671: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.338033: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.338070: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.339995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.340043: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.343080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.343110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.362886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.362934: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.389755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.389806: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.402006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.402061: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.411341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.411392: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.428230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.428280: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.457378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.457424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.471573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.471653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.491433: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.491479: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.519621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.519674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:21.522275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 17:39:21.522312: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 17:39:25.987491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.011624: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.011680: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.012090: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.221388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.221440: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.221466: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.221726: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.223318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.223351: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.223369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.223631: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.225130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.225162: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.225184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.225437: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.248974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.249042: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.249068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.249357: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.260179: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.260226: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.260272: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.260538: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.308864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.308919: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.308945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.309218: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.295733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.309527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.309559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.309875: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.321053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.321101: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.321126: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.321401: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.329955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.330002: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.330025: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.330286: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.356643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.356708: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.356733: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.357027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.437207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.437258: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.437284: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.437565: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.462345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.462400: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.462426: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.462692: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.469705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.469760: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.469786: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.470059: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.564836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.564892: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.564919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.565198: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.626197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.626252: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.626281: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.626543: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.637037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.637091: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.637112: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.637375: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.712795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.712846: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.712872: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.713151: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.713508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.713543: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.713565: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.713819: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 17:39:26.740155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 17:39:26.740213: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 17:39:26.740239: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 17:39:26.740531: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-22 17:39:32,582 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,582 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,583 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,583 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,583 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,585 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,585 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,586 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,608 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 17:39:32,619 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,620 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,621 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,621 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,621 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,621 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,628 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 17:39:32,629 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 17:39:32,636 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,636 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,643 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,643 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,644 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,647 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,648 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,653 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,654 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,655 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,655 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,657 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,657 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,658 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 17:39:32,666 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,671 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,672 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,679 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,680 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,682 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 17:39:32,695 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,716 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,715 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,717 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,720 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,720 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 17:39:32,721 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 17:39:32,721 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 17:39:32,722 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,751 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,753 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,753 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 17:39:32,754 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,795 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,796 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,796 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,796 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,832 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,832 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,833 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,833 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,833 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,834 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 17:39:32,834 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,836 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,837 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,837 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,849 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 17:39:32,860 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 17:39:32,861 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 17:39:32,861 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 17:39:32,861 | connection.py:36 | ChannelConnectivity.READY
2021-11-22 17:46:37.293897: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at maxpooling_op.cc:339 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,30,30,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
DEBUG flower 2021-11-22 17:46:45,869 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 66, in start_client
    client, server_message
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 40, in handle
    return _fit(client, server_msg.fit_ins), 0, True
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 57, in _fit
    fit_res = client.fit(fit_ins)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/numpy_client.py", line 192, in fit
    results = self.numpy_client.fit(parameters, ins.config)
  File "client.py", line 117, in fit
    h = model.fit(x_train, y_train, epochs=5, batch_size=128)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[128,30,30,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
	 [[node gradient_tape/model/max_pooling2d/MaxPool/MaxPoolGrad
 (defined at /home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:464)
]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_3843]

Errors may have originated from an input operation.
Input Source operations connected to node gradient_tape/model/max_pooling2d/MaxPool/MaxPoolGrad:
In[0] model/conv2d_3/Relu (defined at /home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/backend.py:4867)	
In[1] model/max_pooling2d/MaxPool (defined at /home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/layers/pooling.py:362)	
In[2] gradient_tape/model/conv2d_4/Conv2D/Conv2DBackpropInput:

Operation defined at: (most recent call last)
>>>   File "client.py", line 143, in <module>
>>>     fl.client.start_numpy_client("localhost:8080", client=CifarClient())
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
>>>     grpc_max_message_length=grpc_max_message_length,
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 66, in start_client
>>>     client, server_message
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 40, in handle
>>>     return _fit(client, server_msg.fit_ins), 0, True
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/message_handler.py", line 57, in _fit
>>>     fit_res = client.fit(fit_ins)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/numpy_client.py", line 192, in fit
>>>     results = self.numpy_client.fit(parameters, ins.config)
>>> 
>>>   File "client.py", line 117, in fit
>>>     h = model.fit(x_train, y_train, epochs=5, batch_size=128)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/utils/traceback_utils.py", line 64, in error_handler
>>>     return fn(*args, **kwargs)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 1216, in fit
>>>     tmp_logs = self.train_function(iterator)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 878, in train_function
>>>     return step_function(self, iterator)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 867, in step_function
>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 860, in run_step
>>>     outputs = model.train_step(data)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/engine/training.py", line 816, in train_step
>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 531, in minimize
>>>     loss, var_list=var_list, grad_loss=grad_loss, tape=tape)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 583, in _compute_gradients
>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)
>>> 
>>>   File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py", line 464, in _get_gradients
>>>     grads = tape.gradient(loss, var_list, grad_loss)
>>> 
2021-11-22 19:56:23.586068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:23.588870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.808058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.808116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.826633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.826682: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.907963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.908012: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.940833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.940900: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.944715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.944752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.948174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.948210: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.957172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.957210: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.961709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.961747: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.962741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.962774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.964520: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.964551: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:52.971196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:52.971231: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.013174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.013222: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.017288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.017331: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.050341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.050387: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.082966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.083027: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.106456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.106513: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.110551: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.110591: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.133458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.133506: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.177153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.177201: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:53.224651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 19:56:53.224698: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 19:56:58.640922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.643700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.646846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.638602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.638689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.643539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.643795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.642403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.679712: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679712: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679719: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679725: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679731: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679745: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679752: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679781: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679781: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.643116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.679793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679794: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679794: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.679831: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.679854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.644869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.680142: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680143: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680144: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680144: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680149: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680157: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.680168: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.680211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.680593: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.644191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.646163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.681698: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.681708: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.681723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.681739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.682044: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.682089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.645330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.683575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.683620: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.683645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.683938: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.683961: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.687622: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.648203: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.654100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.656948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.691614: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.691627: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.691633: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.691647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.691655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.691660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.691987: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.691987: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.691998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.647895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.650447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.695595: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.695608: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.695624: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.695638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.695941: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.695966: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.650642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.707626: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.707660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.708005: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:56:58.654638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 19:56:58.723639: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 19:56:58.723686: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 19:56:58.724057: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 19:59:07.819004: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818792: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818794: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818787: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818790: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818794: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818795: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818792: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819096: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819014: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819016: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819085: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819019: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819004: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819019: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819016: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819091: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819003: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.819107: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:07.818788: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 30720000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556824: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.556821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557011: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557012: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557025: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557027: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557028: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557031: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557029: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557031: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557123: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557136: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557148: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:14.557158: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.118207: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.128687: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.143758: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.148118: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.171132: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.176433: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.194359: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.196814: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.214024: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.360448: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.376708: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.408703: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.428608: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.444464: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.496502: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.504899: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.517076: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.568955: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.572044: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.596846: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.607569: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.618164: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.627171: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.629585: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.634734: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:19.664482: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.688714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.720621: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.725034: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.743148: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.750248: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.769085: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.788723: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.788880: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:19.807773: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:30.682191: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:29.870846: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:30.708268: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:30.708259: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:29.870819: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:30.682194: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:29.870822: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:30.682188: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:30.708267: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:29.870831: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:30.708259: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:31.629797: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:30.682194: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:31.634274: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.646221: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:29.870827: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.520975: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.679920: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.684086: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:31.703274: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:31.716036: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 72000000 exceeds 10% of free system memory.
2021-11-22 19:59:31.736591: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.742081: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.742359: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
2021-11-22 19:59:31.766841: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 31360000 exceeds 10% of free system memory.
DEBUG flower 2021-11-22 19:59:51,839 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 19:59:51,875 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 19:59:51,895 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 19:59:52,960 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 19:59:52,960 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 19:59:52,969 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:09,788 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:09,789 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:09,789 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:23,440 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:23,450 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:23,544 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:24,550 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:24,550 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:24,551 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:24,820 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:24,820 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:24,825 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:26,466 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:26,466 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 20:01:26,467 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:26,595 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 20:01:26,607 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:26,627 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:26,627 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 20:01:30,220 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:30,223 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 20:01:30,270 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:30,271 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:30,386 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:30,386 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:30,515 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:30,784 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:30,784 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:30,890 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 20:01:31,678 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:31,758 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:31,763 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:31,822 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:31,850 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:31,855 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 20:01:31,926 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:31,926 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:32,039 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:32,043 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:32,044 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:32,085 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:32,932 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:32,956 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:32,962 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:33,085 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:33,088 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:33,103 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:35,411 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:35,429 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 20:01:35,437 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:35,923 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:35,924 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:35,928 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:35,930 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 20:01:36,254 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:01:36,255 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 20:01:36,255 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 20:01:45,147 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 20:01:50,419 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 20:01:53,110 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 20:02:08,126 | connection.py:36 | ChannelConnectivity.TRANSIENT_FAILURE
DEBUG flower 2021-11-22 20:02:08,380 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "failed to connect to all addresses"
	debug_error_string = "{"created":"@1637611327.818766110","description":"Failed to pick subchannel","file":"src/core/ext/filters/client_channel/client_channel.cc","file_line":3158,"referenced_errors":[{"created":"@1637611327.818765321","description":"failed to connect to all addresses","file":"src/core/lib/transport/error_utils.cc","file_line":147,"grpc_status":14}]}"
>
DEBUG flower 2021-11-22 20:02:10,765 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "failed to connect to all addresses"
	debug_error_string = "{"created":"@1637611330.763892521","description":"Failed to pick subchannel","file":"src/core/ext/filters/client_channel/client_channel.cc","file_line":3158,"referenced_errors":[{"created":"@1637611330.763891818","description":"failed to connect to all addresses","file":"src/core/lib/transport/error_utils.cc","file_line":147,"grpc_status":14}]}"
>
DEBUG flower 2021-11-22 20:02:16,380 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "src/python/grpcio/grpc/_cython/_cygrpc/thread.pyx.pxi", line 53, in grpc._cython.cygrpc._run_with_context._run
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 1410, in _poll_connectivity
    _spawn_delivery(state, callbacks)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 1371, in _spawn_delivery
    delivering_thread.start()
  File "src/python/grpcio/grpc/_cython/_cygrpc/fork_posix.pyx.pxi", line 117, in grpc._cython.cygrpc.ForkManagedThread.start
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/threading.py", line 852, in start
    _start_new_thread(self._bootstrap, ())
RuntimeError: can't start new thread

    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "failed to connect to all addresses"
	debug_error_string = "{"created":"@1637611336.256305423","description":"Failed to pick subchannel","file":"src/core/ext/filters/client_channel/client_channel.cc","file_line":3158,"referenced_errors":[{"created":"@1637611336.256304822","description":"failed to connect to all addresses","file":"src/core/lib/transport/error_utils.cc","file_line":147,"grpc_status":14}]}"
>
Segmentation fault
[1211 2118 2438 ... 1972 2281 2016]
create data 0
[1742  740 1811 ... 1424 1797  670]
create data 1
[1835 2403  186 ... 2196 1966 2041]
create data 2
[1078 1751 1842 ...  643 2306 1314]
create data 3
[1046 1209 2333 ...  253 1735 1943]
create data 4
[ 388 1369 2037 ...  314 1893 2004]
create data 5
[ 242  582 2188 ... 2302  485  964]
create data 6
[1552 2450 1952 ...  853 1003  564]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs/20_8_attack_0.8_kmeans/client_19_fault_7.log
DEBUG flower 2021-11-22 20:21:07,871 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 20:21:07,874 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 20:21:07,877 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 20:21:07,877 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637612467.856501922","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637612467.856518788","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637612467.856510387","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
2021-11-22 21:26:28.070228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:28.070283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.645963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.646044: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.656224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.656276: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.658145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.658179: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.678694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.678741: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.683069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.683111: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.706018: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.706065: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.749552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.749612: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.757602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.757657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.773972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.774025: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.774804: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.774847: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.795824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.795870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.801536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.801579: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.833066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.833118: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.863452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.863500: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.911233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.911278: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.919240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.919288: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.933107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.933156: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.952982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.953026: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:56.998601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:56.998657: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:26:57.021212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 21:26:57.021262: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 21:27:01.537011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.537068: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.537093: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.537478: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.595586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.595654: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.595681: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.596068: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.674068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.674130: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.674159: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.674463: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.738238: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.738293: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.738318: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.738583: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.747944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.747998: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.748032: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.748373: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.751986: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.752025: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.752050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.752316: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.767168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.767217: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.767244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.767523: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.775074: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.775120: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.775149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.775429: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.832434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.832489: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.832520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.832814: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.837575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.837625: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.837649: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.837909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.854772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.854820: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.854844: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.855117: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.890707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.890761: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.890792: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.891092: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.938297: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.938353: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.938378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.938644: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.947961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.948021: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.948050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.948354: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.950132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.950169: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.950193: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.950471: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:01.976152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:01.976212: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:01.976237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:01.976505: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:02.014454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:02.014506: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:02.014543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:02.014813: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:02.037716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:02.037776: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:02.037803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:02.038080: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:02.048950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:02.049010: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:02.049046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:02.049310: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 21:27:02.270366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 21:27:02.270421: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 21:27:02.270448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 21:27:02.270706: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-22 21:27:22,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:27:22,162 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:27:22,227 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:27:23,380 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:27:23,380 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:27:23,382 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:28:40,301 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:28:40,301 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 21:28:40,301 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:28:40,395 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:28:43,430 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:28:43,430 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 21:28:43,431 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:28:43,431 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:28:47,396 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:28:47,396 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 21:28:47,397 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:28:47,398 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:28:49,651 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:28:49,652 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:28:49,698 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:28:59,987 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:28:59,995 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:28:59,998 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:01,071 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:01,076 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:01,215 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:02,784 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:02,785 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:02,836 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:04,271 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:04,304 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:04,306 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:08,060 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:08,061 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:08,087 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 21:29:08,518 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:08,542 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:08,542 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:08,691 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:08,697 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:08,701 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:29:10,208 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:10,210 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:10,304 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 21:29:10,384 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:10,432 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:10,443 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:29:12,336 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-22 21:29:12,373 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:12,393 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 21:29:12,394 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:29:15,271 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:15,273 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 21:29:15,310 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:16,373 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-22 21:29:16,373 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:16,395 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:29:19,349 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:19,349 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 21:29:19,350 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:19,350 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 21:29:19,394 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 21:29:19,395 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 21:29:19,395 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 21:29:19,396 | connection.py:36 | ChannelConnectivity.READY
2021-11-22 21:42:50.841119: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
Segmentation fault
[1253 2446  375 ... 2181 2315  582]
create data 0
[1448 2053  381 ... 1178  972 2438]
create data 1
[ 409  309 2174 ... 1320  583 1068]
create data 2
[ 863 1066 1725 ...  279 1463  438]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs/20_4_attack_0.8_kmeans/client_19_fault_3.log
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,959 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-22 21:58:24,959 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,959 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,960 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,960 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 21:58:24,960 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-22 21:58:24,960 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,960 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 21:58:24,960 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,961 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-22 21:58:24,961 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,961 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,961 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-22 21:58:24,961 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-22 21:58:24,961 | app.py:72 | Disconnect and shut down
2021-11-22 22:10:31.627007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:10:31.627051: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.299639: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.299709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.375221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.375274: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.389977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.390027: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.399903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.399955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.417099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.417149: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.434158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.434203: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.448347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.448399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.486359: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.486408: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.487464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.487499: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.512880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.512947: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.598564: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.598609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.603373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.603424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.616384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.616432: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.623949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.623996: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.629082: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.629124: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.630184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.630221: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.638150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.638192: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.650240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.650291: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.651770: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.651808: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:00.664638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-22 22:11:00.664683: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-22 22:11:05.096714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.096775: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.096802: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.097099: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.397055: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.397116: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.397142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.397422: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.450145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.450202: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.450229: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.450505: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.450516: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.450560: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.450581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.450846: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.464749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.464803: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.464830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.465110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.482358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.482412: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.482439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.482717: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.497084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.497142: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.497171: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.497492: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.522515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.522572: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.522599: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.522694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.522731: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.522752: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.522855: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.523009: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.523952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.524002: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.524027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.524356: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.545037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.545099: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.545127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.545382: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.563480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.575626: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.575689: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.576060: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.588354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.588404: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.588429: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.588699: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.622183: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.622242: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.622274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.622604: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.628036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.628076: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.628099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.628342: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.695834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.695888: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.695916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.696251: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.712560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.712616: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.712642: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.712941: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.720887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.720944: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.720972: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.721264: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.764367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.764435: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.764463: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.764751: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-22 22:11:05.850692: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-22 22:11:05.850751: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-22 22:11:05.850778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-22 22:11:05.851033: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-22 22:11:11,827 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,839 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 22:11:11,844 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,854 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,854 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 22:11:11,855 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,856 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,855 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,856 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,856 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,857 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,857 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 22:11:11,863 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,867 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-22 22:11:11,871 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 22:11:11,871 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 22:11:11,872 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 22:11:11,875 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-22 22:11:11,885 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,887 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,887 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,887 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,890 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,895 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,896 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,912 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,912 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,913 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,914 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,919 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,919 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,921 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,921 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,926 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,927 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,928 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,936 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,940 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,941 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,942 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,942 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,943 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,943 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,947 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,950 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,950 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,959 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,959 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,960 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,960 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,960 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,961 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-22 22:11:11,961 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,961 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-22 22:11:11,961 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,963 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,961 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,969 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,969 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,970 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,977 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,977 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,982 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,983 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,983 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,986 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:11,997 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:11,998 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:11,998 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:11,999 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-22 22:11:12,011 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:11:12,012 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-22 22:11:12,012 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-22 22:11:12,012 | connection.py:36 | ChannelConnectivity.READY
2021-11-22 22:18:21.243760: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at maxpooling_op.cc:339 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[128,30,30,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,832 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,833 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,832 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-22 22:58:25,843 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817247763","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
DEBUG flower 2021-11-22 22:58:26,034 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 22:58:26,034 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 22:58:26,034 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 22:58:26,037 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 22:58:26,037 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-22 22:58:26,043 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817262668","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817247623","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817251586","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817248102","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817323938","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637621905.817249198","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
[1585 2035  547 ... 1425  368 1717]
create data 0
[1718  513 1998 ... 2372  119 2016]
create data 1
[1765  740 1719 ...  193  815 2192]
create data 2
[1990 1043  375 ...  717  214    1]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs/20_4_attack_0.8/client_19_fault_3.log
2021-11-23 00:33:06.937287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:06.937332: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.097023: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.097077: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.156377: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.156433: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.194823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.194872: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.483420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.483464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.502070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.502116: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.523582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.523631: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.531242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.531301: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.562174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.562218: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.589963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.590010: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.609255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.609299: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.616414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.616463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.627621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.627672: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.638155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.638199: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.649936: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.649981: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.662119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.662167: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.666958: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.667006: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.688339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.688384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.698170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.698225: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.757847: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.757894: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:35.795346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 00:33:35.795394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 00:33:40.019456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.019511: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.023592: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.023997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.200365: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.200423: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.200448: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.200711: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.281545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.281604: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.281633: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.281908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.331815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.331869: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.331906: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.332186: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.351407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.351471: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.351504: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.375922: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.394141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.394190: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.394215: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.394497: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.432421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.432472: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.432508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.432772: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.455432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.455490: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.455515: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.455786: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.488291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.488344: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.488374: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.488668: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.517503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.517562: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.517589: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.517883: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.522848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.522899: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.522924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.523190: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.524248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.524294: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.524321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.524621: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.553946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.554016: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.554047: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.554334: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.591121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.591169: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.591196: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.591452: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.636503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.636559: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.636586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.636841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.647627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.647688: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.647718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.647999: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.713672: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.713724: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.713748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.713996: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.734394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.734451: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.734474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.734734: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.741651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.741695: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.741719: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.741977: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 00:33:40.974779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 00:33:40.974837: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 00:33:40.974863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 00:33:40.975140: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-23 00:33:46,723 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,731 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,731 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,732 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,741 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,747 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,783 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,783 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,784 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,784 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,790 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,791 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,791 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,792 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,795 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,796 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,798 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,803 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,804 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,818 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,819 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,820 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,820 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,831 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,833 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,843 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,844 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,843 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,848 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,859 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,859 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,859 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,871 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,871 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,878 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,878 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,878 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,879 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,879 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,879 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,880 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,880 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,880 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,881 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,881 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,882 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,884 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,884 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,884 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,886 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,886 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,886 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,898 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-23 00:33:46,900 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,901 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,901 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,902 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,902 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,903 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,903 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,919 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,919 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,920 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,920 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 00:33:46,927 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,927 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,928 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,928 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,946 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,946 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 00:33:46,947 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 00:33:46,947 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,977 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 00:33:46,977 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 00:33:46,978 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 00:33:46,978 | connection.py:36 | ChannelConnectivity.READY
2021-11-23 00:44:17.346284: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-23 00:44:17.346644: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-23 00:49:58.403585: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-23 00:56:23.561442: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-23 00:56:23.583621: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-23 01:08:49.627591: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:18:38,200 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 01:18:38,201 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 01:18:38,201 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 01:18:38,201 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 01:18:38,202 | app.py:72 | Disconnect and shut down
create data 0
create data 1
create data 2
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_0_fault_-1.log & python client.py -c 1 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_1_fault_-1.log & python client.py -c 2 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_2_fault_-1.log & python client.py -c 3 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_3_fault_-1.log & python client.py -c 4 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_4_fault_-1.log & python client.py -c 5 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_5_fault_-1.log & python client.py -c 6 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_6_fault_-1.log & python client.py -c 7 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_7_fault_-1.log & python client.py -c 8 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_8_fault_-1.log & python client.py -c 9 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_9_fault_-1.log & python client.py -c 10 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_10_fault_-1.log & python client.py -c 11 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_11_fault_-1.log & python client.py -c 12 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_12_fault_-1.log & python client.py -c 13 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_13_fault_-1.log & python client.py -c 14 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_14_fault_-1.log & python client.py -c 15 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_15_fault_-1.log & python client.py -c 16 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_16_fault_-1.log & python client.py -c 17 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_17_fault_-1.log & python client.py -c 18 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_18_fault_-1.log & python client.py -c 19 -f -1 -m cnn -e local -n 20_0_attack_0.8 > ./logs/20_0_attack_0.8/client_19_fault_-1.log
2021-11-23 01:36:20.016118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:20.016167: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.491358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.491415: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.581292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.581345: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.582075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.582114: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.589163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.589205: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.640943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.641005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.694723: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.694771: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.706704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.706751: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.711051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.711098: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.712778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.712817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.812031: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.812079: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.817952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.818004: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.820243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.820281: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.856356: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.856404: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.869110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.869156: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.883223: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.883270: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.899090: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.899145: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.928002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.928047: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.959626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.959675: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:48.981464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:48.981517: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:49.007899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 01:36:49.007943: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 01:36:53.412471: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.412523: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.412547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.412821: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.420312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.420360: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.420385: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.420664: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.526266: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.526338: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.526380: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.526692: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.599674: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.599726: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.599753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.600045: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.656163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.656214: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.656237: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.656492: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.672324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.672378: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.672402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.672689: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.795248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.795295: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.795319: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.795602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.810698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.810749: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.810774: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.811043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.811745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.811778: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.811799: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.812112: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.813510: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.813541: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.813562: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.813833: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.819134: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.819178: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.819200: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.819455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.847051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.847107: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.847132: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.847414: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.855091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.855142: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.855165: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.855418: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.922358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.922414: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.922440: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.922716: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.942051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.942109: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.942136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.942405: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.950910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.950964: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.950992: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.951257: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:53.968413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:53.968475: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:53.968511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:53.968786: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:54.009389: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:54.009443: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:54.009468: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:54.009732: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:54.133625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:54.133677: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:54.133701: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:54.133966: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 01:36:54.263402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 01:36:54.263461: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 01:36:54.263487: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 01:36:54.287874: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-23 01:37:16,103 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:37:16,107 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:37:16,147 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:37:16,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:37:16,949 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 01:37:16,949 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:37:17,161 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 01:38:45,448 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:45,450 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:45,495 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:46,459 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:46,461 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:46,519 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:47,491 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:47,503 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 01:38:47,543 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:47,543 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:52,454 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:52,484 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:52,549 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:54,266 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:54,267 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:54,278 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:56,834 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:56,835 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:56,917 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:57,284 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:57,285 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:57,285 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 01:38:58,342 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:38:58,387 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:58,387 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 01:38:59,807 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:38:59,807 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 01:38:59,857 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:38:59,857 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:01,700 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:01,705 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:01,756 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 01:39:02,913 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:02,946 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:02,946 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:05,275 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:05,289 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:05,289 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:05,449 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:05,451 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:05,464 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 01:39:09,083 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:09,103 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:09,119 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 01:39:10,171 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:10,183 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:10,219 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 01:39:17,440 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:17,447 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:17,548 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:21,173 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:21,184 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 01:39:21,241 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 01:39:21,539 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 01:39:21,646 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:39:21,650 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,151 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,152 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,152 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,152 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 01:45:27,154 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,154 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,155 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,156 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,157 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129601601","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129497974","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129496783","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129497040","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129566320","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129498409","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129558977","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129602120","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129561157","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129497063","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129574666","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
DEBUG flower 2021-11-23 01:45:27,352 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,352 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,353 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,353 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,354 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,356 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129563031","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
DEBUG flower 2021-11-23 01:45:27,360 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 01:45:27,360 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129559398","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129499865","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
DEBUG flower 2021-11-23 01:45:27,373 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129560159","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129497455","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129562365","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129595594","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129504372","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637631927.129594393","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
create data 0
create data 1
create data 2
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_0_fault_-1.log & python client.py -c 1 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_1_fault_-1.log & python client.py -c 2 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_2_fault_-1.log & python client.py -c 3 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_3_fault_-1.log & python client.py -c 4 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_4_fault_-1.log & python client.py -c 5 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_5_fault_-1.log & python client.py -c 6 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_6_fault_-1.log & python client.py -c 7 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_7_fault_-1.log & python client.py -c 8 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_8_fault_-1.log & python client.py -c 9 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_9_fault_-1.log & python client.py -c 10 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_10_fault_-1.log & python client.py -c 11 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_11_fault_-1.log & python client.py -c 12 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_12_fault_-1.log & python client.py -c 13 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_13_fault_-1.log & python client.py -c 14 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_14_fault_-1.log & python client.py -c 15 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_15_fault_-1.log & python client.py -c 16 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_16_fault_-1.log & python client.py -c 17 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_17_fault_-1.log & python client.py -c 18 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_18_fault_-1.log & python client.py -c 19 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_19_fault_-1.log
2021-11-23 15:10:05.052180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:05.052232: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.626414: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.626465: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.680432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.680482: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.681810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.681845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.707227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.707277: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.718468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.718518: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.787601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.787653: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.790149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.790186: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.796724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.796762: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.799418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.799450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.808653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.808690: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.826431: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.826480: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.846772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.846822: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.853116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.853163: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.853803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.853838: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.866363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.866409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.909571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.909623: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.915248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.915297: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.925262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.925312: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.956623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.956676: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:33.967402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 15:10:33.967464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 15:10:38.456713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.456773: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.456797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.457089: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.491143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.491198: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.491225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.491511: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.589046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.589102: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.589128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.589409: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.661862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.661916: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.661938: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.662215: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.692734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.692799: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.692824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.693121: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.716400: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.716456: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.716482: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.716757: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.724816: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.724863: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.724885: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.725164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.726079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.726114: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.726137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.726414: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.750542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.750597: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.750622: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.750881: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.767922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.767972: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.767995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.768251: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.817895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.817951: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.817980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.818246: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.840330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.840381: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.840407: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.840673: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.874303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.874354: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.874377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.874651: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.908664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.908713: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.908738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.909011: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.920729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.920787: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.920814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.921078: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:38.941705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:38.941762: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:38.941789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:38.942049: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:39.072550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:39.072606: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:39.072632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:39.072891: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:39.093959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:39.094013: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:39.094039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:39.094305: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:39.113982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:39.114044: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:39.114071: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:39.114349: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 15:10:39.141303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 15:10:39.141358: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 15:10:39.141386: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 15:10:39.141673: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-23 15:11:02,719 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:11:02,719 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:11:02,779 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 15:11:03,000 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:11:03,046 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:11:03,047 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 15:12:23,660 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:23,660 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 15:12:23,723 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:23,729 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:27,079 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:27,080 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:27,135 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:31,812 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:31,812 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:31,859 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:33,222 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:33,223 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:33,298 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:33,347 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:33,359 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:33,385 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:37,051 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:37,052 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:37,058 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:39,101 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:39,102 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 15:12:39,102 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:39,156 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 15:12:39,230 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:39,230 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 15:12:39,245 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:39,348 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:41,058 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 15:12:41,062 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:41,109 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:44,491 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:44,492 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:44,493 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 15:12:45,102 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:45,103 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:45,109 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 15:12:53,417 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:53,422 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:53,455 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:55,716 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:55,716 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 15:12:55,718 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:55,790 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:56,449 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:56,450 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:56,552 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:56,915 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:56,982 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:12:57,033 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:57,840 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:12:57,840 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 15:12:57,841 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:12:57,842 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 15:13:01,290 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:13:01,292 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 15:13:01,327 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 15:13:01,365 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 15:13:16,709 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 15:13:16,710 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 15:13:16,710 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
create data 0
create data 1
create data 2
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_0_fault_-1.log & python client.py -c 1 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_1_fault_-1.log & python client.py -c 2 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_2_fault_-1.log & python client.py -c 3 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_3_fault_-1.log & python client.py -c 4 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_4_fault_-1.log & python client.py -c 5 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_5_fault_-1.log & python client.py -c 6 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_6_fault_-1.log & python client.py -c 7 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_7_fault_-1.log & python client.py -c 8 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_8_fault_-1.log & python client.py -c 9 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_9_fault_-1.log & python client.py -c 10 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_10_fault_-1.log & python client.py -c 11 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_11_fault_-1.log & python client.py -c 12 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_12_fault_-1.log & python client.py -c 13 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_13_fault_-1.log & python client.py -c 14 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_14_fault_-1.log & python client.py -c 15 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_15_fault_-1.log & python client.py -c 16 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_16_fault_-1.log & python client.py -c 17 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_17_fault_-1.log & python client.py -c 18 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_18_fault_-1.log & python client.py -c 19 -f -1 -m cnn -e local -n 20_0_attack_0.8_kmeans -k > ./logs/20_0_attack_0.8_kmeans/client_19_fault_-1.log
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,650 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 15:44:19,649 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,651 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 15:44:19,651 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 15:44:19,651 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,651 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 15:44:19,651 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,651 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 15:44:19,652 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,652 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 15:44:19,652 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 15:44:19,652 | app.py:72 | Disconnect and shut down
2021-11-23 18:55:09.246174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:09.246226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.332536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.332592: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.344124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.344170: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.363982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.364041: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.403490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.403561: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.407885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.407939: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.425607: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.425658: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.446337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.446384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.449452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.449494: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.457336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.457382: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.458010: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.458062: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.468543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.468586: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.475038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.475088: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.491871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.491924: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.511175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.511226: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.521422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.521472: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.531747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.531795: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.545869: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.545921: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.561810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.561857: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.565418: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.565460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:38.630474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-23 18:55:38.630520: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-23 18:55:43.114861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.114917: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.114941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.115234: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.223392: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.223448: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.223472: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.223765: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.273247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.273303: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.273328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.273602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.328165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.328220: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.328248: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.328524: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.401496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.401563: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.401592: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.401879: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.402517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.402550: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.402572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.402834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.429140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.429195: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.429220: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.429484: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.448815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.448868: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.448893: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.449187: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.450765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.450801: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.450820: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.451073: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.461848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.461916: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.461944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.462243: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.469008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.469065: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.469088: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.469358: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.485671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.485728: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.485756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.486038: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.496838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.496890: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.496912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.497175: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.546216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.546264: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.546290: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.546551: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.568953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.569008: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.569031: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.569318: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.598736: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.598789: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.598815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.599064: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.695351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.695408: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.695434: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.695716: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.705974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.706027: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.706053: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.706328: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.716851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.716916: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.716941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.717209: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-23 18:55:43.854234: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-23 18:55:43.854287: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-23 18:55:43.854314: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-23 18:55:43.854587: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-23 18:56:07,839 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:56:07,839 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:56:07,840 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:56:07,840 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:56:07,886 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-23 18:56:07,903 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:24,243 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:24,244 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:24,260 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:31,695 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:31,697 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:31,731 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:32,289 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:32,303 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:32,339 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:33,307 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:33,312 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:33,351 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:34,602 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:34,603 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:34,739 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:34,938 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:34,938 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 18:57:34,939 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:34,940 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:57:36,183 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:36,187 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:36,189 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:36,951 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:36,951 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:36,951 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:37,575 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:37,576 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:37,664 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:38,094 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:38,094 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:38,115 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:38,401 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:38,401 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:38,423 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:39,060 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:39,065 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:39,148 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:39,158 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:39,158 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 18:57:39,183 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:39,246 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:57:39,972 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:39,973 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 18:57:39,983 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:39,998 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:57:41,063 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:41,064 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 18:57:41,069 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:41,074 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:57:41,561 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:41,561 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:41,562 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:41,976 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:41,977 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-23 18:57:41,977 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-23 18:57:41,978 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-23 18:57:42,067 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-23 18:57:42,067 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-23 18:57:42,068 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-23 18:57:42,068 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
[ 474 1256  944 ...  297 1775 2152]
create data 0
[1104  893  162 ... 1476 2240 1044]
create data 1
[1647 2148  195 ...  448 1293 2249]
create data 2
[2085    0  983 ...  318 1880 2192]
create data 3
[2436   43 1067 ... 2208 1331  568]
create data 4
[2036 1848 1741 ... 1994 2341 1441]
create data 5
[2120 2024  298 ... 1513 1340  937]
create data 6
[1616  762  320 ... 1833  946  818]
create data 7
[2357  729 2276 ... 1449  801  585]
create data 8
[1869 1696  992 ... 1515 1975 2086]
create data 9
[ 878  243  555 ...  852  933 1883]
create data 10
[ 893  190  384 ...  237  233 1779]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs/20_12_attack_0.8_kmeans/client_19_fault_11.log
DEBUG flower 2021-11-23 19:23:13,368 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,367 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,368 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,367 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,367 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,368 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,368 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,371 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-23 19:23:13,374 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-23 19:23:13,374 | app.py:72 | Disconnect and shut down
2021-11-24 03:28:22.424028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:22.424072: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.363797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.363852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.373955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.374011: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.465989: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.466040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.471710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.471761: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.478856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.478902: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.479344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.479367: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.497548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.497595: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.510335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.510380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.512307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.512341: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.533613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.533663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.546426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.546473: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.577886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.577930: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.600946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.600992: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.608101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.608146: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.619500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.619557: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.627242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.627286: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.649202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.649246: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.650802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.650836: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.655856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.655889: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:51.666022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 03:28:51.666080: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 03:28:56.057888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.058013: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.058039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.058333: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.295659: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.295707: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.295730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.295980: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.313620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.313674: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.313699: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.313993: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.330328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.330387: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.330416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.330727: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.387244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.387318: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.387350: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.391481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.391541: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.391570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.391846: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.399741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.421016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.421065: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.421095: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.421376: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.442316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.442368: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.442394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.442662: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.476016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.476066: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.476090: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.476351: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.493855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.493905: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.493931: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.493983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.494020: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.494042: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.494199: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.494302: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.497362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.497399: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.497419: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.497691: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.498264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.498293: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.498312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.498556: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.550065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.550118: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.550156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.550427: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.596465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.596524: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.596551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.596856: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.614590: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.614636: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.614660: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.614904: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.621335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.621377: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.621400: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.621650: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.671653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.671706: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.671731: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.671980: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.840556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.840613: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.840639: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.840923: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 03:28:56.970391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 03:28:56.970445: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 03:28:56.970472: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 03:28:56.970731: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-24 03:29:03,450 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,456 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 03:29:03,463 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 03:29:03,464 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,467 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,467 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,477 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,477 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,483 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,487 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,487 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,488 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,488 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,488 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 03:29:03,500 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 03:29:03,503 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,505 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,505 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,506 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,507 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,507 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,507 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,509 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 03:29:03,510 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,510 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,510 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,511 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,512 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,512 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,511 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 03:29:03,512 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 03:29:03,514 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 03:29:03,515 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,515 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,515 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,516 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,515 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,516 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,516 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,516 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,519 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,520 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,527 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,531 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,532 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,532 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,539 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 03:29:03,540 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,540 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,541 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,542 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 03:29:03,542 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,543 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,544 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,545 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,547 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,547 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,547 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,549 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 03:29:03,550 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,550 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,551 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 03:29:03,552 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 03:29:03,552 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,568 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,568 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 03:29:03,594 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 03:29:03,595 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 03:29:03,595 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 03:29:03,595 | app.py:61 | Opened (insecure) gRPC connection
2021-11-24 03:35:42.662541: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 03:41:04.384347: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 03:41:04.383797: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.013861: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.019457: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 03:51:19.013963: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.014438: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.025029: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.013934: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-24 03:51:19.013881: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 03:51:19.022910: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 04:03:06,225 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 04:03:06,225 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 04:03:06,225 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 04:03:06,225 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 04:03:06,225 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 04:03:06,225 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 04:03:06,226 | app.py:72 | Disconnect and shut down
[1332 1650  202 ... 1213 2334  415]
create data 0
[ 666 1128 1252 ... 2382 2361  975]
create data 1
[ 551 2483   72 ... 1621 2464  823]
create data 2
[ 682 1822  106 ... 2444  621 1375]
create data 3
[ 611 1290  489 ... 1481 1195   95]
create data 4
[ 512  902 2467 ...   36  270 2198]
create data 5
[1354 1662 2231 ... 1539 2151 2183]
create data 6
[ 806  766  915 ... 1076 1996  538]
create data 7
[1290  851  264 ... 1710  322 1363]
create data 8
[2127  749 2012 ...  349 2021 1685]
create data 9
[ 470  586   32 ... 1637 2235  678]
create data 10
[1016 1054  955 ...  391 1990 2407]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs/20_12_attack_0.8/client_19_fault_11.log
2021-11-24 04:25:34.540321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:25:34.540369: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.642773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.642832: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.664838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.664893: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.676215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.676266: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.698065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.698114: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.706653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.706720: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.718144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.718191: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.736975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.737022: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.774012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.774060: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.784949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.784993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.804368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.804419: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.810774: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.810823: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.824769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.824817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.846722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.846780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.858664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.858709: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.964434: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.964479: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.969051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.969094: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.972251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.972293: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:03.983860: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:03.983909: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:04.000085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:04.000139: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:04.004421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 04:26:04.004469: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 04:26:08.576124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.576175: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.576199: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.576475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.584632: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.584688: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.584712: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.584996: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.702474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.702534: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.702571: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.702830: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.716983: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.717039: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.717068: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.717353: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.728154: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.728200: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.728222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.728504: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.736429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.736468: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.736492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.736764: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.743037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.743075: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.743097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.743356: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.766076: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.766131: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.766161: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.766455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.767971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.768012: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.768033: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.768363: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.858557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.858619: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.858649: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.858946: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.863805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.863842: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.863864: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.864119: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.905289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.905345: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.905370: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.905655: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.923514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.923592: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.923617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.923889: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.939765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.939813: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.939837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.940110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:08.982452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:08.982505: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:08.982529: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:08.982786: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:09.025925: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:09.025988: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:09.026021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:09.026318: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:09.030637: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:09.030692: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:09.030718: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:09.030983: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:09.055053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:09.055111: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:09.055137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:09.055398: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:09.077809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:09.077864: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:09.077892: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:09.078174: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 04:26:09.084956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 04:26:09.084997: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 04:26:09.085031: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 04:26:09.085285: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-24 04:26:15,079 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,080 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,096 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 04:26:15,101 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 04:26:15,113 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 04:26:15,115 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,115 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,116 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,120 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,127 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,131 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,135 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,136 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,136 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,143 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,144 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 04:26:15,141 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,146 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,151 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,159 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,160 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,160 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,160 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,160 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,175 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,176 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 04:26:15,176 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 04:26:15,187 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,188 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,188 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,202 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,203 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,203 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 04:26:15,211 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,220 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,220 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,221 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,221 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,221 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,223 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,223 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 04:26:15,224 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,252 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,255 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,255 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 04:26:15,256 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,256 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,257 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,257 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 04:26:15,258 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,258 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,260 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,260 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,261 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,261 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,264 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,265 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 04:26:15,265 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,266 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,280 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,281 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,281 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 04:26:15,281 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,281 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 04:26:15,281 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 04:26:15,281 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,289 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,290 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,290 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 04:26:15,290 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 04:26:15,302 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 04:26:15,302 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 04:26:15,303 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 04:26:15,303 | app.py:61 | Opened (insecure) gRPC connection
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
2021-11-24 04:42:22.512242: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 04:42:22.511362: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-24 04:42:22.514574: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,444 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,445 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,447 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 05:09:21,445 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 05:09:21,445 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 05:09:21,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 05:09:21,448 | app.py:72 | Disconnect and shut down
[1495 2123 2290 ...   92  856 2243]
create data 0
[ 457 1681  716 ... 1738  909  395]
create data 1
[ 486 1859 1352 ... 2308 2224 2071]
create data 2
[ 122 1106 1749 ...  142 2493 2173]
create data 3
[ 717  575 1540 ... 1611 1589 1539]
create data 4
[2092  187 1540 ...  749 1133 1460]
create data 5
[ 531 2448 1566 ...  318 2125 1813]
create data 6
[ 257  460 2134 ...  325  956  225]
create data 7
[2001 1109 1044 ... 2292 2151 2071]
create data 8
[1747 1302  379 ... 2305  557  393]
create data 9
[2067 2353 1002 ...  681 1759 1004]
create data 10
[2172 1319 1936 ... 1965 2218  877]
create data 11
[ 447 2361 2395 ...  742  406 1926]
create data 12
[1291 1930  893 ... 1383 1619 1522]
create data 13
[ 499 2179 1846 ... 1463  971 1624]
create data 14
[1689  790 1835 ...  810  338 1171]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs/20_16_attack_0.8/client_19_fault_15.log
2021-11-24 19:51:08.447206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:08.447252: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.774789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.774846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.796169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.796221: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.804486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.804548: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.808982: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.809029: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.825449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.825498: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.840143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.840199: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.843714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.843762: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.887876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.887873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.887921: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.887933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.924677: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.924727: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.927873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.927913: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.941901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.941955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:37.998846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:37.998908: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.025030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.025082: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.032256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.032304: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.041216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.041260: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.047174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.047221: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.071582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.071629: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.108589: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.108650: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:38.217475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 19:51:38.217532: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 19:51:42.587122: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.587189: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.587217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.587513: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.660688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.660739: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.660773: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.661079: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.740319: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.740370: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.740394: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.740657: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.797838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.797894: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.797918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.798193: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.821775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.821826: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.821850: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.822128: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.845169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.845299: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.845348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.845632: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.859733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.859790: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.859816: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.860173: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.860971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.861017: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.861039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.861381: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.899824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.899874: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.899898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.900157: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.920947: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.921004: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.921028: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.921295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:42.989836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:42.989900: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:42.989926: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:42.990221: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.007960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.008012: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.008039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.008315: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.019248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.019303: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.019327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.047682: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.073990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.074047: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.074073: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.074321: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.106107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.106160: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.106186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.106455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.122726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.122788: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.122815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.123084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.127855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.127897: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.127920: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.128166: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.220581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.220639: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.220665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.220949: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.228790: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.228840: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.228863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.229125: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 19:51:43.318363: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 19:51:43.318417: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 19:51:43.318444: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 19:51:43.318711: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-24 19:51:49,203 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 19:51:49,204 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,204 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,211 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,211 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,212 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,223 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,225 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,227 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,235 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,258 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,258 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,259 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,265 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 19:51:49,267 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,267 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,315 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,319 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,320 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,329 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,330 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 19:51:49,330 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,381 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,382 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,390 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,395 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,402 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,413 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,437 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,437 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,438 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,441 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,443 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,443 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,444 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,444 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,445 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,445 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,445 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,445 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,445 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,447 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,447 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,448 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,448 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 19:51:49,457 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,458 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,458 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,458 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,459 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,460 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,467 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,468 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,468 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,481 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,483 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,483 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,483 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,501 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,502 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,502 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,502 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,505 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,507 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,507 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,531 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,532 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 19:51:49,533 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 19:51:49,533 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 19:51:49,543 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 19:51:49,544 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 19:51:49,544 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-24 19:51:49,544 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:03:21,977 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 22:03:54,075 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:52,792 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:52,792 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:54,340 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:53,167 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:53,167 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:54,657 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:54,657 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:53,759 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:54,754 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:54,754 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:55,354 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:03:55,576 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 22:03:56,756 | connection.py:36 | ChannelConnectivity.IDLE
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791110.577928213","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "src/python/grpcio/grpc/_cython/_cygrpc/thread.pyx.pxi", line 53, in grpc._cython.cygrpc._run_with_context._run
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 1392, in _poll_connectivity
    time.time() + 0.2)
  File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 512, in grpc._cython.cygrpc.Channel.watch_connectivity_state
  File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 377, in grpc._cython.cygrpc._watch_connectivity_state
  File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 385, in grpc._cython.cygrpc._watch_connectivity_state
ValueError: Cannot invoke RPC: Channel closed!

    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791095.455783124","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,157 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218629777","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,415 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791106.198545801","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,421 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791095.455764995","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,492 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218619940","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,498 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791134.636111361","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,503 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218663376","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,543 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218666785","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,700 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218673813","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,749 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218612747","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,774 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218636127","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,801 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218671739","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-11-24 22:04:37,928 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218628861","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
[2051 1943 1481 ...   87 1243  822]
create data 0
[2488 1519 1438 ...   54 2423 1771]
create data 1
[ 403 1919 1599 ... 2129 2121 2005]
create data 2
[1833 2032 2233 ...  646   89 1256]
create data 3
[1146  960 1441 ...  444 1198 1497]
create data 4
[1657 2046  634 ... 2252 2060  510]
create data 5
[ 650 2296 1038 ...  622  969  652]
create data 6
[1304 2204 1931 ... 1054 1946  618]
create data 7
[1308 1343 2412 ... 2453   83  924]
create data 8
[ 381 1420 1855 ...   96  904 1935]
create data 9
[1365 2455 1951 ...  927 1358  800]
create data 10
[1894 1544 2250 ...  192  810  500]
create data 11
[ 998 1444 2027 ... 2361 1016  205]
create data 12
[2364 1456 2112 ...  878 2235    7]
create data 13
[1031 1166 1617 ...  513 1575 1066]
create data 14
[ 870 1769 2005 ... 1748  979  846]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_19_fault_15.log
DEBUG flower 2021-11-24 22:04:39,249 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1637791123.218616044","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
2021-11-24 22:39:35.778725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:39:35.780282: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.352866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.352919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.386379: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.386424: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.412597: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.412645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.444619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.444667: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.453490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.453542: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.473654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.473703: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.483123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.483170: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.485158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.485190: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.492536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.492578: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.537289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.537332: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.537531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.537562: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.542236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.542275: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.552628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.552670: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.563997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.564040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.616366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.616409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.627706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.627748: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.637874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.637915: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.675051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.675105: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.676891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.676904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-24 22:40:06.676917: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:06.676928: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-24 22:40:11.314402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.314453: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.314479: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.338786: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.348368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.348412: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.348435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.348715: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.350078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.350112: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.350134: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.350394: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.363880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.363922: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.363945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.364206: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.433473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.433522: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.433547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.433783: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.442030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.442071: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.442098: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.442344: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.511423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.511474: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.511501: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.511762: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.513458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.513492: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.513516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.513770: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.515889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.515923: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.515945: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.516199: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.549717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.549764: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.549788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.550027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.582595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.582648: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.582678: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.582968: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.599758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.599810: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.599839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.600129: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.616780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.616831: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.616861: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.617164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.634806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.634874: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.634899: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.635197: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.651180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.651233: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.651258: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.651509: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.654562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.654597: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.654616: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.670968: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.750862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.750916: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.750943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.751184: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.760454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.760518: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.760546: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.760791: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.762729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.770849: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.770939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.771284: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-24 22:40:11.914016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-24 22:40:11.914070: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-24 22:40:11.914097: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-24 22:40:11.914337: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,948 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,949 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,950 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-24 22:40:58,950 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-24 22:40:58,971 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,971 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,972 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,972 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,972 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,972 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,972 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,974 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,974 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-24 22:40:58,973 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,972 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:58,974 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:58,973 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,006 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,007 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,007 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-24 22:40:59,007 | connection.py:36 | ChannelConnectivity.READY
2021-11-24 22:49:47.120439: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
Killed
[1135 1228  253 ...  435 1326 1312]
create data 0
[ 438 2279  874 ...  967  265 2306]
create data 1
[2086  783 2031 ... 1480 2375  677]
create data 2
[1631  700 1754 ... 1061 1842 2111]
create data 3
[1128  499 2255 ...  775 1991 1531]
create data 4
[1190 2463  926 ... 1221 1146 1385]
create data 5
[ 756 1634  971 ... 1550 2017 1402]
create data 6
[1013 1340 2077 ...  422  987 1586]
create data 7
[ 870  301  164 ... 1493  224   44]
create data 8
[2006 2101  572 ...  636 2145  924]
create data 9
[1319 1663  642 ...   43  157  854]
create data 10
[ 764  812 2127 ... 1463 1450  943]
create data 11
[  49 2289  356 ...  663  404  615]
create data 12
[1039 1018 2196 ... 2351  574  864]
create data 13
[1094  299  117 ... 1386 1077 1705]
create data 14
[ 646 1204  592 ...  159 2237  452]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8 > ./logs_e1/20_16_attack_0.8/client_19_fault_15.log
2021-11-24 22:55:07.986318: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
DEBUG flower 2021-11-24 23:00:44,091 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,091 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 23:00:44,091 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 23:00:44,091 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,091 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 23:00:44,091 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 23:00:44,092 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 23:00:44,092 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 23:00:44,092 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,092 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 23:00:44,092 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 23:00:44,092 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,092 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 23:00:44,092 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 23:00:44,095 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 23:00:44,095 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-24 23:00:44,095 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,095 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-24 23:00:44,095 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-24 23:00:44,095 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 23:00:44,095 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-24 23:00:44,095 | app.py:72 | Disconnect and shut down
2021-11-25 00:30:43.458563: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:30:43.458639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.487500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.487553: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.501025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.501080: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.532402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.532453: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.538778: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.538846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.541714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.541748: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.552036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.552075: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.614059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.614114: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.618709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.626785: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.634803: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.634814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.635314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.635341: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.666050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.666100: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.684940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.684982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.707455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.707497: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.708616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.708650: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.748437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.748491: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.749515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.749547: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.771410: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.771457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.784214: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.784258: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.831029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.831079: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:12.906713: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 00:31:12.922811: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 00:31:17.433789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.433851: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.433878: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.434219: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.458960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.459018: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.459045: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.459369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.478454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.478505: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.478529: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.478814: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.496446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.496499: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.496526: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.496834: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.508969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.509023: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.509046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.509340: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.527646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.527696: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.527722: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.528004: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.547707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.547763: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.547789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.548057: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.579314: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.579372: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.579403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.579708: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.653011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.653068: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.653095: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.653362: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.656081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.656133: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.656164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.656459: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.670101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.670162: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.670189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.670450: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.690313: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.690381: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.690411: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.690709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.735696: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.735750: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.735776: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.736041: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.748936: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.748994: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.749026: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.749324: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.750514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.750554: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.750577: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.752782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.752814: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.752833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.753097: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.754952: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.879612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.879673: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.879703: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.879988: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.889630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.889682: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.889711: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.889989: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:17.892848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:17.892893: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:17.892915: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:17.893194: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 00:31:18.086832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 00:31:18.086904: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 00:31:18.086930: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 00:31:18.087271: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-25 00:31:49,212 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:31:49,214 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:31:49,217 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:31:49,222 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:31:49,246 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 00:31:49,294 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:15,078 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:15,084 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:15,134 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:19,545 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:19,546 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:19,547 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:22,024 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:22,026 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:22,070 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:23,702 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:23,703 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 00:33:23,754 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:23,786 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:28,317 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:28,317 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 00:33:28,371 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:28,577 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:33:29,900 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:29,900 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 00:33:29,901 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:29,914 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:33:30,046 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 00:33:30,058 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:30,113 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:33:30,420 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:30,421 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:30,480 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:30,497 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:30,498 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:30,502 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:32,726 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:32,730 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:33:32,739 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:32,744 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:32,767 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 00:33:32,810 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:33,224 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:33,224 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 00:33:33,225 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:33,260 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:33,575 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:33,575 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:33,576 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:36,215 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:36,219 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:36,220 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 00:33:39,079 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:39,084 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:39,086 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:39,571 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:39,572 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:39,644 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:39,888 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:39,888 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:39,914 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 00:33:40,838 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 00:33:40,842 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 00:33:40,866 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 00:33:41,093 | app.py:61 | Opened (insecure) gRPC connection
2021-11-25 00:38:27.858084: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-25 00:38:27.869602: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-25 00:38:27.858065: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,771 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 00:51:50,772 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,769 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 00:51:50,770 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 00:51:50,772 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,772 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,772 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 00:51:50,772 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 00:51:50,773 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 00:51:50,773 | app.py:72 | Disconnect and shut down
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-4-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-9-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-13-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-6-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-15-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-16-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-19-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-10-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-1-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-0-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-11-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-3-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-18-fault-15.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_16_attack_0.8_kmeans/history-14-fault-15.pkl'
[1155 2357  773 ... 2251  782 2004]
create data 0
[ 289 1782  972 ... 2483  872 1651]
create data 1
[1152 1495 1131 ...  357   78   76]
create data 2
[1113  101  253 ... 1664 2194 1124]
create data 3
[ 448 1420   64 ... 1395 1234 1381]
create data 4
[ 147  250 1365 ...  225 1948 1863]
create data 5
[2190 1543  271 ... 2059  107  704]
create data 6
[1042  716 2175 ... 1236 1454 1106]
create data 7
[1752  103 1857 ... 1477  812 1017]
create data 8
[  89 1112 2233 ... 2177 1878  895]
create data 9
[2471 1902  337 ... 1484 1509 2411]
create data 10
[2497 1897 2477 ... 1793 2211 2340]
create data 11
[ 255 1269  930 ... 1740  848 2360]
create data 12
[2017  480 1919 ...  201  769 1273]
create data 13
[ 737  521  260 ... 1520 1494 2329]
create data 14
[1419  934  476 ... 1432  139 2261]
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_0_fault_15.log & python client.py -c 1 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_1_fault_15.log & python client.py -c 2 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_2_fault_15.log & python client.py -c 3 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_3_fault_15.log & python client.py -c 4 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_4_fault_15.log & python client.py -c 5 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_5_fault_15.log & python client.py -c 6 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_6_fault_15.log & python client.py -c 7 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_7_fault_15.log & python client.py -c 8 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_8_fault_15.log & python client.py -c 9 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_9_fault_15.log & python client.py -c 10 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_10_fault_15.log & python client.py -c 11 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_11_fault_15.log & python client.py -c 12 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_12_fault_15.log & python client.py -c 13 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_13_fault_15.log & python client.py -c 14 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_14_fault_15.log & python client.py -c 15 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_15_fault_15.log & python client.py -c 16 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_16_fault_15.log & python client.py -c 17 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_17_fault_15.log & python client.py -c 18 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_18_fault_15.log & python client.py -c 19 -f 15 -m cnn -e local -n 20_16_attack_0.8_kmeans -k > ./logs_e1/20_16_attack_0.8_kmeans/client_19_fault_15.log
2021-11-25 02:29:55.755262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:29:55.755307: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.460384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.460442: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.553684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.553746: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.590211: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.590259: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.604435: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.604483: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.624438: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.624485: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.618719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.634829: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.644268: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.644321: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.649422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.649469: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.703675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.703729: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.724458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.724508: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.750372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.750423: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.764724: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.764770: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.775946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.775993: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.834344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.834394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.849121: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.849166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.925709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.925756: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.935141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.935191: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.947176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.947228: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:24.998519: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:24.998564: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:25.011682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 02:30:25.011727: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 02:30:29.386158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.386226: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.386259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.386589: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.498115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.498170: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.498194: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.498467: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.510528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.510585: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.510613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.510927: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.529967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.530016: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.530043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.530330: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.603235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.603294: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.603324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.603617: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.607202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.607244: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.607264: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.607541: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.613383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.613422: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.613444: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.613701: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.640384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.640436: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.640460: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.640710: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.739504: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.739555: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.739581: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.739844: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.747821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.747868: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.747891: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.748148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.783811: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.783875: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.783901: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.784194: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.811187: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.811242: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.811292: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.811661: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.815944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.815981: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.816002: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.816252: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.846873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.846932: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.846962: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.847307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.885933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.885988: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.886017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.886295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:29.891210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:29.891248: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:29.891270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:29.891526: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:30.003450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:30.003503: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:30.003528: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:30.003776: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:30.020074: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:30.020131: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:30.020156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:30.020417: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:30.075232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:30.075288: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:30.075313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:30.075565: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 02:30:30.082800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 02:30:30.082853: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 02:30:30.082877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 02:30:30.083141: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-25 02:30:53,906 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:30:53,914 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:30:53,954 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 02:30:53,968 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:30:53,970 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:30:54,034 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:14,470 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:14,471 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:14,487 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:16,315 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:16,316 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 02:32:16,315 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:16,430 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:18,570 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:18,570 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:18,573 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:23,247 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:23,250 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:23,281 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 02:32:23,489 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:23,524 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:23,524 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:25,325 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:25,334 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:25,376 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 02:32:26,085 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:26,097 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:26,166 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:29,550 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:29,551 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:29,618 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:31,096 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:31,096 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:31,157 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:33,708 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:33,708 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 02:32:33,709 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:33,851 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:34,262 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:34,263 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:34,267 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:35,247 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:35,248 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 02:32:35,253 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:35,334 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:35,356 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 02:32:35,360 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:35,365 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:35,365 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:35,393 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:35,393 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:38,365 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:38,366 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:38,395 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:38,726 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 02:32:38,726 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:38,728 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 02:32:38,749 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:32:40,677 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:32:40,678 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 02:32:40,694 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:41,942 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 02:32:41,957 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 02:32:41,960 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,573 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,574 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,574 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,575 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551907118","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551899041","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818345","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818464","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818808","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551904527","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
DEBUG flower 2021-11-25 02:47:47,776 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,777 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,777 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,778 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,786 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,788 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,795 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,803 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 02:47:47,803 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818409","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818347","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551898762","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818688","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551904297","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551898554","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551819643","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551929918","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 826, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "{"created":"@1637808467.551818411","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"Socket closed","grpc_status":14}"
>
[1597 1714  262 ... 2369 2395 2366]
create data 0
[121 397 808 ... 937 371 945]
create data 1
[1896 1871 2443 ...  189 1206 2134]
create data 2
[1477  694   82 ...  952 1697 1040]
create data 3
[1340   64 1967 ... 2229 1944   83]
create data 4
[1389   75 2363 ...  437  608  457]
create data 5
[ 676 1911 2336 ...  595 1769 2194]
create data 6
[1462 2327 2305 ... 1249  919  905]
create data 7
[2251  482 1767 ...  352 1903  731]
create data 8
[ 561  442  488 ... 2024 1972 2056]
create data 9
[ 402 1563  415 ... 1924 1726 1718]
create data 10
[ 727  854  559 ... 2400 1501 1390]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8_kmeans -k > ./logs_e1/20_12_attack_0.8_kmeans/client_19_fault_11.log
2021-11-25 21:45:31.692783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:45:31.692824: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.822442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.822492: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.842864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.842923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.873614: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.873663: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.873864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.873899: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.875664: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.875694: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.884437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.884471: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.901025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.901068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.955641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.955687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.960196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.960238: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:00.969061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:00.969109: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.015538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.015587: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.018824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.018867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.027301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.027353: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.084737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.084777: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.183903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.183947: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.201039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.201086: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.221273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.221322: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.234039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.234086: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.243647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.243695: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:01.267751: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 21:46:01.267818: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 21:46:05.734653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.734709: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.734749: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.735043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.755280: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.755353: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.755381: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.755683: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.798287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.798345: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.798373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.798668: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.826210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.826260: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.826286: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.826557: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.894193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.894247: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.894274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.894565: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.907162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.907220: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.907247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.907602: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.936957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.937014: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.937040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.937345: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.938918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.938959: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.938983: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.939298: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.962243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.962289: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.962313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.962576: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:05.997477: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:05.997527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:05.997552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:05.997832: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.044450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.044513: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.044538: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.044833: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.059940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.059992: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.060015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.060277: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.060299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.060338: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.060361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.060636: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.077459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.077510: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.077535: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.077808: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.132660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.132713: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.132736: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.133005: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.281866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.281925: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.281952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.282228: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.315210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.315262: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.315289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.315558: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.328676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.328734: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.328761: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.329032: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.332116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.332163: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.332187: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.332451: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 21:46:06.392092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 21:46:06.392151: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 21:46:06.392191: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 21:46:06.392474: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-25 21:46:12,454 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,454 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 21:46:12,457 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,462 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 21:46:12,463 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,466 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,487 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,488 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,488 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,496 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,496 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,499 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 21:46:12,520 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,529 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,531 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,546 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,546 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,547 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 21:46:12,559 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,579 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 21:46:12,584 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,584 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,585 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,586 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,586 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,586 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,586 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,587 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 21:46:12,602 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,619 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,619 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,626 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,630 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,630 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,631 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 21:46:12,636 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,636 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,637 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,637 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,638 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,639 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,639 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,640 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,640 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 21:46:12,640 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 21:46:12,640 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,641 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,641 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,641 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 21:46:12,642 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,643 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,643 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,643 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,643 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,644 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,644 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,645 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,651 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,652 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,653 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,655 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,657 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,658 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,658 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,659 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 21:46:12,696 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,697 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,697 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 21:46:12,698 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,699 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,700 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 21:46:12,700 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 21:46:12,700 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,720 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 21:46:12,721 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 21:46:12,721 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 21:46:12,721 | connection.py:36 | ChannelConnectivity.READY
2021-11-25 21:49:37.625497: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
Segmentation fault
[ 462 2201  176 ... 2392  718 2334]
create data 0
[1192  956 1453 ...  275 2380 1399]
create data 1
[1838  619 1432 ... 1412 1692 1764]
create data 2
[1484  508 2322 ... 2304  672  689]
create data 3
[1787 1944  426 ...  161 1386   64]
create data 4
[ 262 1938 2454 ... 1136  721 2331]
create data 5
[ 258  548  403 ... 1571  752 2051]
create data 6
[ 519  384 1726 ... 1651 1896 1912]
create data 7
[ 488 1314  589 ...  901  311 2096]
create data 8
[ 624  735  481 ... 1203  437 1759]
create data 9
[1035 1972 1300 ... 1281 2313 1508]
create data 10
[1274 1334 1557 ...   48  759  892]
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_0_fault_11.log & python client.py -c 1 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_1_fault_11.log & python client.py -c 2 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_2_fault_11.log & python client.py -c 3 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_3_fault_11.log & python client.py -c 4 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_4_fault_11.log & python client.py -c 5 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_5_fault_11.log & python client.py -c 6 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_6_fault_11.log & python client.py -c 7 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_7_fault_11.log & python client.py -c 8 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_8_fault_11.log & python client.py -c 9 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_9_fault_11.log & python client.py -c 10 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_10_fault_11.log & python client.py -c 11 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_11_fault_11.log & python client.py -c 12 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_12_fault_11.log & python client.py -c 13 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_13_fault_11.log & python client.py -c 14 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_14_fault_11.log & python client.py -c 15 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_15_fault_11.log & python client.py -c 16 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_16_fault_11.log & python client.py -c 17 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_17_fault_11.log & python client.py -c 18 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_18_fault_11.log & python client.py -c 19 -f 11 -m cnn -e local -n 20_12_attack_0.8 > ./logs_e1/20_12_attack_0.8/client_19_fault_11.log
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:04:18,670 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:04:18,671 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 22:04:18,670 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:04:18,671 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 22:04:18,671 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:04:18,671 | app.py:72 | Disconnect and shut down
2021-11-25 22:36:17.371576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:17.371624: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.246912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.246982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.265023: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.265076: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.265270: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.265293: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.267787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.267828: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.342873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.342925: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.370384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.370435: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.394903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.394954: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.404567: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.404619: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.427449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.427499: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.442170: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.442218: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.454833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.454885: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.458626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.458670: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.468049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.468098: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.470870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.470910: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.499940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.499985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.506868: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.506918: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.519481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.519524: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.542647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.542695: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.593604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.593652: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:46.601386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 22:36:46.601431: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 22:36:51.206640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.206705: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.206734: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.207066: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.283652: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.283703: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.283730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.284005: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.294199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.294257: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.294287: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.294582: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.333500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.333552: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.333575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.333947: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.344290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.344337: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.344362: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.344655: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.353913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.353976: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.354006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.354301: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.394089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.394140: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.394167: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.394455: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.418606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.418662: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.418689: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.418971: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.425475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.425523: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.425550: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.425820: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.435929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.435985: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.436017: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.436339: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.441888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.441936: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.441961: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.442227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.526092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.526145: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.526172: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.526440: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.538475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.538530: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.538560: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.538880: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.572856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.572910: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.572937: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.573205: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.599056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.599119: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.599157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.599497: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.602533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.602574: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.602603: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.607169: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.612843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.612886: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.612912: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.613195: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.626546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.626600: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.626625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.626926: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.635642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.635693: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.635720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.636020: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 22:36:51.749332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 22:36:51.749383: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 22:36:51.749411: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 22:36:51.749688: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-25 22:36:57,772 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,776 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,777 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,780 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:57,781 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,790 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,791 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 22:36:57,793 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:57,794 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 22:36:57,795 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 22:36:57,803 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,806 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,836 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,869 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,870 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,876 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,876 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:57,876 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 22:36:57,877 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,894 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,902 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:57,902 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,903 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,903 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:57,931 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,931 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,938 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,942 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,955 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,955 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:57,970 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 22:36:57,970 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,973 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,973 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:57,974 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,980 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,981 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,990 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 22:36:57,991 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:57,991 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:57,992 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:57,996 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:57,996 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,025 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,026 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:58,029 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,048 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,050 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 22:36:58,051 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 22:36:58,051 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,057 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,058 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:58,058 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,059 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:58,076 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,076 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:58,077 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,077 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:58,091 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,092 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:58,092 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,093 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:58,136 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,137 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:58,137 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,137 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 22:36:58,166 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 22:36:58,167 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 22:36:58,168 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 22:36:58,168 | connection.py:36 | ChannelConnectivity.READY
2021-11-25 22:46:13.902349: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-25 22:46:13.904353: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-25 22:52:19.795360: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-25 22:56:48,147 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-25 22:56:48,147 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-25 22:56:48,148 | app.py:72 | Disconnect and shut down
[2048 1115 1555 ...  732  529 1938]
create data 0
[ 920  902  550 ... 2293 1689 2063]
create data 1
[ 717  441 2116 ...  317 1277 2350]
create data 2
[ 778 2104   79 ...  271 1007 2367]
create data 3
[1645 2120 1408 ... 1961 1913 1671]
create data 4
[ 377 1668  189 ...  236  785 2498]
create data 5
[ 708  680 1270 ...  153 1148  731]
create data 6
[ 868  534 2415 ...  910  340  982]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_19_fault_7.log
2021-11-25 23:23:53.902316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:23:53.902389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:24:46.408472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:24:46.408526: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.234980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.235073: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.349227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.349279: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.354638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.354691: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.355917: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.355955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.356953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.356987: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.375017: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.375071: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.376540: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.376577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.416261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.416317: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.493707: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.493764: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.524595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.524641: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.527599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.527647: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.530020: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.530061: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.531809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.531865: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.542886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.542936: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.552662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.552708: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.615681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.615732: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.632185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.632236: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.722181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.722225: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.827737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.827785: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:13.856888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-25 23:25:13.856936: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-25 23:25:18.112918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.112981: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.113007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.113296: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.283712: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.283774: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.283804: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.284111: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.299543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.299588: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.299613: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.299871: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.359500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.359553: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.359583: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.359890: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.408558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.408617: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.408643: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.408931: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.419945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.420002: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.420027: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.420327: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.441061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.441108: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.441131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.441410: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.494133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.494187: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.494212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.494487: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.502193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.502245: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.502281: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.502569: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.569594: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.569650: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.569688: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.569948: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.633891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.633952: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.633982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.634269: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.637582: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.637639: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.637670: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.637963: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.643760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.643805: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.643830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.644092: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.646097: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.646133: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.646156: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.646411: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.677417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.677467: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.677492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.677771: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.727335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.727396: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.727426: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.727705: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.769883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.769932: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.769958: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.770212: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.914409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.914461: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.914490: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.938780: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:18.985654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:18.985708: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:18.985738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:18.986028: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-25 23:25:19.093412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-25 23:25:19.093473: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-25 23:25:19.093499: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-25 23:25:19.093770: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-25 23:25:24,878 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,878 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,879 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:24,879 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,879 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,880 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:24,880 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:24,887 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,888 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 23:25:24,888 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,888 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:24,893 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,902 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:24,906 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:24,906 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 23:25:24,907 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,910 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:24,919 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,919 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,919 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,919 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:24,920 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:24,920 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:24,926 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 23:25:24,934 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 23:25:24,935 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,945 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,945 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:24,945 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:24,946 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 23:25:24,966 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-25 23:25:24,967 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:24,990 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 23:25:24,993 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,006 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:25,018 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,018 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,018 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,019 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,019 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 23:25:25,031 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,048 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,048 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 23:25:25,053 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,054 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,054 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 23:25:25,055 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,055 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:25,058 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,062 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,079 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-25 23:25:25,079 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,079 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,099 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,099 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 23:25:25,100 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,100 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,109 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,109 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-25 23:25:25,110 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,110 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-25 23:25:25,156 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,157 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:25,158 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:25,158 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,170 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,170 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:25,171 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:25,171 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-25 23:25:25,177 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-25 23:25:25,177 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-25 23:25:25,177 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-25 23:25:25,178 | app.py:61 | Opened (insecure) gRPC connection
Killed
[1244  575 2453 ... 2256 1883 1151]
create data 0
[ 804  368  320 ... 1747 1041  470]
create data 1
[2075 2419  767 ... 1771 1561  823]
create data 2
[2025  233 1315 ...  268 1372  914]
create data 3
[ 941  251  799 ... 1209  492  896]
create data 4
[ 923 1891 1421 ...   38  963 1602]
create data 5
[1764  339 2001 ... 1089  809 1213]
create data 6
[1278 2498 1159 ... 1460   52 2422]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_19_fault_7.log
2021-11-26 00:48:19.668579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:19.668637: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.305373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.305428: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.452139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.452198: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.466859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.466925: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.474298: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.474346: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.562599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.562650: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.565324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.565373: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.578167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.578215: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.580154: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.580205: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.583528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.583567: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.598333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.598380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.599300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.599334: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.610034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.610088: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.619323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.619367: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.650158: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.650207: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.668979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.669042: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.669143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.669180: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.679603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.679652: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.680191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.680229: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.690130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.690175: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:48.737006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 00:48:48.737052: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 00:48:53.396586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.396651: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.396679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.396985: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.428794: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.428860: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.428892: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.429195: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.492200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.492262: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.492289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.492575: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.498824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.498877: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.498902: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.499172: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.551569: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.551621: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.551649: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.551937: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.561244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.561300: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.561338: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.561553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.561594: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.561617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.561623: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.561887: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.585324: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.585378: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.585405: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.585675: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.632256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.632317: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.632347: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.632639: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.646620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.646674: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.646700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.646997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.650899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.650952: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.650978: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.651298: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.658773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.658832: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.658855: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.659118: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.670891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.670945: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.670971: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.674914: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.737219: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.737275: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.737303: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.737572: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.756084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.756142: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.756169: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.756490: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.792489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.792548: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.792574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.792839: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.800938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.800984: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.801010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.801290: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.825908: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.825963: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.825990: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.826262: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:53.828494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:53.828532: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:53.828555: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:53.828808: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 00:48:54.023183: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 00:48:54.023239: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 00:48:54.023265: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 00:48:54.023546: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-26 00:49:20,376 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,376 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,376 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,376 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,377 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,378 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 00:49:20,479 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,479 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,479 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,480 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,480 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,480 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,480 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,481 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,481 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 00:49:20,482 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 00:49:20,483 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 00:49:20,482 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,483 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 00:49:20,483 | connection.py:36 | ChannelConnectivity.READY
2021-11-26 00:54:43.546363: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-26 00:54:43.559412: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 00:54:43.546138: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 00:54:43.554863: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-26 01:33:27.696405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:27.696811: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.878243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.878302: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.913837: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.913887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.920402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.920478: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.937125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.937173: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.976206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.976256: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:56.981267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:56.981310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.057273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.057323: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.064992: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.065041: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.069809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.069852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.080129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.080174: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.086597: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.086643: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.117841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.117887: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.120592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.120635: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.132591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.132640: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.163397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.163442: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.172029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.172076: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.195120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.195172: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.199905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.199948: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.265058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.265111: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:33:57.273867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 01:33:57.273917: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 01:34:01.858829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.858899: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.858931: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.859307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:01.870430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.870478: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.870505: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.882904: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:01.915668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.915734: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.915766: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.916080: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:01.924332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.924385: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.924414: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.924723: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:01.959952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.960013: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.960042: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.960319: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:01.972650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:01.972703: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:01.972728: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:01.973035: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.076287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.076360: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.076389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.076663: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.141462: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.141514: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.141538: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.141804: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.153877: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.153928: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.153955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.154219: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.166071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.166123: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.166151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.166440: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.180943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.180995: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.181021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.181332: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.218140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.218201: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.218225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.218487: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.250029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.250082: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.250107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.250115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.250154: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.250176: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.250415: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.250447: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.265401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.265460: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.265489: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.265774: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.268472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.268524: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.268547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.268809: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.314588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.314638: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.314663: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.327112: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.344626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.344691: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.344717: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.344998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.416797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.416848: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.416874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.417140: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 01:34:02.536852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 01:34:02.536910: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 01:34:02.536941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 01:34:02.537229: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-26 01:34:15,497 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,497 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,497 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,498 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,499 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 01:34:15,595 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,595 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,595 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,596 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,597 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 01:34:15,597 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,597 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 01:34:15,597 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 01:34:15,597 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,597 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 01:34:15,598 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,598 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,599 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,599 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 01:34:15,599 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,599 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,599 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 01:34:15,599 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 01:34:15,599 | connection.py:36 | ChannelConnectivity.READY
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
2021-11-26 01:45:28.790009: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 01:45:28.791067: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 01:50:21.500322: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-26 01:50:21.484347: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 01:50:21.485484: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 01:54:32,151 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 01:54:32,152 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 01:54:32,151 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 01:54:32,152 | app.py:72 | Disconnect and shut down
[ 957 1224  932 ... 2381 2419 1764]
create data 0
[1007 1370   65 ... 1914 1640  434]
create data 1
[ 866  711 1171 ...  822 2252 2270]
create data 2
[1838 1287  265 ... 2082 1930 1324]
create data 3
[1558 1731 1442 ... 2155 2265 1329]
create data 4
[ 496 1272 1741 ...  579  291 1028]
create data 5
[ 141  814   99 ...  803   36 2300]
create data 6
[1165 1679 1494 ... 2260 1495  101]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8 > ./logs_e1/20_8_attack_0.8/client_19_fault_7.log
2021-11-26 02:37:48.310261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:37:48.310307: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.145746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.145798: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.185962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.186012: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.190905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.190947: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.212642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.212688: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.225033: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.225076: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.282241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.282288: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.284384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.284421: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.286876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.286911: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.296537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.296576: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.316785: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.316849: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.328502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.328548: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.381704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.381757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.401997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.402044: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.409423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.409466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.412366: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.412408: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.416168: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.416207: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.435264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.435317: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.466524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.466570: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.470211: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.470247: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:17.489412: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 02:38:17.489457: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 02:38:22.013890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.013953: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.013980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.014311: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.032452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.032504: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.032527: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.032800: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.189474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.189523: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.189550: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.189580: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.189622: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.189645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.189813: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.189909: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.283634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.283682: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.283705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.284001: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.288459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.288498: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.288521: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.288789: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.318572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.318622: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.318648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.318935: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.321193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.321237: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.321259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.321507: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.325538: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.325573: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.325595: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.325860: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.329772: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.329815: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.329833: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.330084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.342769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.342821: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.342846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.351424: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.356956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.356998: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.357022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.357301: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.416258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.416316: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.416341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.416621: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.419662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.419723: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.419753: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.420056: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.431737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.431782: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.431807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.432116: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.435928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.435962: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.435985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.436268: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.465296: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.465349: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.465375: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.465629: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.529232: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.529289: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.529315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.529567: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.584617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.584673: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.584721: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.584985: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 02:38:22.595930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 02:38:22.595981: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 02:38:22.596006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 02:38:22.596300: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-26 02:38:49,694 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:38:49,698 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:38:49,710 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:38:49,718 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:38:49,754 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 02:38:49,767 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:14,386 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:14,390 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:14,398 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:16,531 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:16,531 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:16,532 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:16,822 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:16,826 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:16,860 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:18,750 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:18,754 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:18,770 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:21,757 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:21,758 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:21,840 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 02:40:21,994 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:22,033 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:22,033 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:22,138 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:22,270 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:22,278 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:25,739 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-26 02:40:25,741 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:25,776 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:26,442 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:26,442 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 02:40:26,449 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:26,584 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:27,123 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:27,123 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 02:40:27,143 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:27,188 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 02:40:27,975 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:28,012 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:28,017 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:28,318 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:28,326 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:28,327 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 02:40:29,367 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:29,410 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:29,410 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:30,168 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:30,195 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:30,195 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:30,713 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:30,713 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 02:40:30,727 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:30,748 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:30,959 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:30,980 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 02:40:30,984 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:31,114 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 02:40:31,114 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 02:40:31,115 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-26 02:40:31,116 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:31,117 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 02:40:31,118 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 02:40:31,118 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 02:40:31,119 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:00:18,129 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,129 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,129 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,129 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,129 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,130 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,130 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,130 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 03:00:18,130 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,131 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,131 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:00:18,131 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:00:18,133 | app.py:72 | Disconnect and shut down
[ 747  751 2288 ... 1217  355  977]
create data 0
[ 458 2464   34 ... 1690 2274  853]
create data 1
[ 629 1453  987 ...  470  658  124]
create data 2
[2290 2002  903 ... 1810  613  756]
create data 3
[ 316 1813 1389 ...  269 1158 1625]
create data 4
[   9 2071 1055 ... 1693 2017 1671]
create data 5
[ 765 1319  616 ...  162  883 1858]
create data 6
[   2  617 1857 ... 1273 1287 1822]
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_0_fault_7.log & python client.py -c 1 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_1_fault_7.log & python client.py -c 2 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_2_fault_7.log & python client.py -c 3 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_3_fault_7.log & python client.py -c 4 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_4_fault_7.log & python client.py -c 5 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_5_fault_7.log & python client.py -c 6 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_6_fault_7.log & python client.py -c 7 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_7_fault_7.log & python client.py -c 8 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_8_fault_7.log & python client.py -c 9 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_9_fault_7.log & python client.py -c 10 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_10_fault_7.log & python client.py -c 11 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_11_fault_7.log & python client.py -c 12 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_12_fault_7.log & python client.py -c 13 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_13_fault_7.log & python client.py -c 14 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_14_fault_7.log & python client.py -c 15 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_15_fault_7.log & python client.py -c 16 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_16_fault_7.log & python client.py -c 17 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_17_fault_7.log & python client.py -c 18 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_18_fault_7.log & python client.py -c 19 -f 7 -m cnn -e local -n 20_8_attack_0.8_kmeans -k > ./logs_e1/20_8_attack_0.8_kmeans/client_19_fault_7.log
2021-11-26 03:40:27.193350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:27.193415: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.761863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.761919: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.778834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.778899: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.796028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.796076: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.798396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.798430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.819911: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.819957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.874509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.874566: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.884404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.884452: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.913236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.913293: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.928388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.928438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:55.962928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:55.962985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.008374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.008453: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.012918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.012963: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.015337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.015370: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.034274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.034322: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.038673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.038716: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.053422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.053466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.091202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.091250: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.123099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.123151: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.130845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.130889: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:40:56.264629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 03:40:56.264682: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 03:41:00.814282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.814338: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.814378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.814671: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.833666: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.833715: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.833739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.834017: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.835162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.835197: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.835218: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.835464: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.854441: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.854494: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.854519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.859321: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.875893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.875946: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.875975: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.876282: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.900346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.900403: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.900427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.900718: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.939063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.939122: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.939160: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.939438: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:00.955851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:00.955911: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:00.955940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:00.956250: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.002703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.002778: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.002809: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.003093: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.018228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.018283: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.018315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.018643: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.036056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.036111: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.036138: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.036436: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.104525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.104587: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.104619: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.104906: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.163844: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.163905: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.163936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.164247: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.168290: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.168343: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.168369: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.168663: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.185734: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.185785: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.185812: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.186088: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.237761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.237813: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.237839: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.238108: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.240989: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.241031: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.241058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.241348: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.261663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.261725: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.261752: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.262015: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.281258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.281316: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.281341: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.281646: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 03:41:01.337858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 03:41:01.337918: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 03:41:01.337944: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 03:41:01.338218: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-26 03:41:29,818 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:41:29,820 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:41:29,837 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:41:29,842 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:41:29,858 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:41:29,929 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:42:56,307 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:42:56,307 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 03:42:56,443 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:42:56,462 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:42:59,859 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:42:59,860 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:42:59,938 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:01,040 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:01,051 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 03:43:01,065 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:01,141 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:01,766 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:01,767 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:01,775 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:04,496 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:04,496 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 03:43:04,497 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:04,578 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:04,648 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:04,648 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 03:43:04,650 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:04,662 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:05,173 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:05,173 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:05,244 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 03:43:07,624 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:07,675 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:07,675 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:09,666 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:09,666 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:09,667 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:10,195 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:10,195 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:10,224 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:10,275 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:10,276 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 03:43:10,306 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:10,329 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:12,348 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:12,348 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:12,352 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:15,181 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:15,181 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 03:43:15,225 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:15,246 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:16,466 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:16,495 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:16,498 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:16,605 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:16,606 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 03:43:16,661 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:16,675 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:21,090 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:21,091 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 03:43:21,122 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 03:43:21,696 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:21,703 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 03:43:21,709 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 03:43:25,138 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-26 03:43:25,144 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 03:43:25,154 | connection.py:36 | ChannelConnectivity.READY
2021-11-26 03:50:18.215092: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
2021-11-26 03:50:18.226611: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
2021-11-26 03:50:18.213193: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
Aborted
[ 422  619 2138 ... 2318  131  315]
create data 0
[1463 2264  406 ... 1766 1901  179]
create data 1
[1192 2336 2289 ... 1363  695  969]
create data 2
[1919 1783  545 ... 1346 1947 2067]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_19_fault_3.log
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,447 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 03:59:13,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,447 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,448 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,448 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 03:59:13,449 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 03:59:13,449 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 03:59:13,449 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 03:59:13,449 | app.py:72 | Disconnect and shut down
2021-11-26 04:05:41.275373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:05:41.275416: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.692671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.692725: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.794395: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.794446: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.831338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.831389: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.885643: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.885696: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.917078: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.917132: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.959405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.959462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:09.979870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:09.979923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.001058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.001107: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.003250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.003298: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.007278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.007322: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.011336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.011379: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.039711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.039708: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.039756: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.039772: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.080199: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.080248: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.089064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.089117: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.101896: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.101945: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.111216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.111261: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.130287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.130335: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.175253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.175298: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:10.182808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:06:10.182862: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:06:14.609479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.609538: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.609564: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.609900: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.754289: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.754343: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.754372: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.754690: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.853426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.853478: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.853506: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.853783: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.875725: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.875776: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.875803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.875802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.875841: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.875862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.876068: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.876164: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.923585: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.923641: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.923667: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.923934: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.941742: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.941791: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.941818: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.942080: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.979459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.979507: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.979532: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.979807: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:14.996704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:14.996759: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:14.996785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:14.997084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.010186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.010234: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.010259: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.010521: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.049586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.049650: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.049682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.049995: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.099616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.099673: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.099702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.099965: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.115196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.115258: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.115285: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.115544: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.176829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.176903: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.176933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.177226: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.181323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.181371: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.181396: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.181665: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.170730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.186823: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.186858: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.187192: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.192447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.192485: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.192510: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.192795: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.209612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.209675: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.209707: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.209987: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.309863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.309911: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.309938: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.310208: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:06:15.534905: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:06:15.534961: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:06:15.534990: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:06:15.535342: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO flower 2021-11-26 04:06:21,139 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,154 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,158 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,235 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,235 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,235 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,235 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,246 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,258 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,301 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,310 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,311 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,343 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,343 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:06:21,344 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,344 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,345 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,351 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,354 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:06:21,362 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,363 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,367 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:06:21,367 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:06:21,383 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,398 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,398 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,400 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,410 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,410 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,487 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,487 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,488 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,500 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,501 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,511 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,514 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,514 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:06:21,515 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,515 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,519 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,520 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,520 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,521 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,521 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,522 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:06:21,522 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,523 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,525 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,527 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,527 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,527 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:06:21,529 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,555 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-11-26 04:06:21,556 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,558 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,577 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,577 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:06:21,577 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,578 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,578 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,578 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:06:21,578 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,581 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,582 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,582 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,592 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,592 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,593 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,594 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,594 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:06:21,651 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:06:21,651 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:06:21,652 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:06:21,652 | connection.py:36 | ChannelConnectivity.READY
2021-11-26 04:13:31.765929: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_iterator_resource creation via pthread_create() failed.
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,185 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 04:26:13,186 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,186 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 04:26:13,186 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 04:26:13,189 | app.py:72 | Disconnect and shut down
[2319  912 1024 ...   32 1309 2041]
create data 0
[1659  110 2446 ... 1494  606 1753]
create data 1
[1878 2225  945 ... 1051 2064 1950]
create data 2
[1756  382 2254 ... 2457 2035 1015]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.8 > ./logs_e1/20_4_attack_0.8/client_19_fault_3.log
2021-11-26 04:42:32.242411: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:42:32.242459: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.014556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.014613: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.019822: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.019873: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.032676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.032730: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.051228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.051275: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.057416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.057467: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.090949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.091008: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.130592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.130643: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.137867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.137922: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.154125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.154181: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.158123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.158172: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.160202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.160250: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.162245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.162280: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.173416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.173464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.184464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.184510: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.191966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.192015: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.213884: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.213932: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.223458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.223519: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.256496: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.256550: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.305485: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.305547: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:01.315032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-26 04:43:01.315083: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-26 04:43:05.954378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:05.954438: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:05.954465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:05.964374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:05.964424: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:05.964450: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:05.964736: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:05.970919: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.011184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.011239: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.011264: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.011611: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.067910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.067974: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.068000: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.068289: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.104760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.104823: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.104851: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.105140: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.209061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.209125: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.209154: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.209424: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.226515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.226572: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.226598: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.226896: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.270584: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.270637: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.270661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.299074: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.321706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.321762: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.321789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.322118: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.331152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.331208: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.331236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.331515: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.344335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.344388: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.344415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.344698: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.347427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.347471: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.347494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.347777: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.347883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.347921: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.347941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.348218: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.401738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.401808: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.401837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.402119: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.413803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.413860: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.413886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.414161: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.448741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.448798: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.448824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.449084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.452978: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.453019: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.453043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.453326: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.481749: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.481803: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.481830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.482122: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.493139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.493191: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.493217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.493489: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-26 04:43:06.596729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-11-26 04:43:06.596785: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-11-26 04:43:06.596814: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-11-26 04:43:06.597122: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-11-26 04:43:31,310 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:43:31,321 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:43:31,334 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:43:31,346 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:43:31,394 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:43:31,415 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:44,258 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:44,298 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:44:44,306 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:52,371 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:52,377 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:44:52,423 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:55,038 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:55,062 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:44:55,190 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:55,766 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:55,766 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:44:55,766 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:44:55,785 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:55,806 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:55,807 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:44:55,912 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:55,990 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:44:55,998 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:44:56,032 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:56,115 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:44:56,115 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:44:56,139 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:44:56,159 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:45:00,367 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:00,368 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:45:00,368 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:00,423 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:45:00,425 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:00,425 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:00,425 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:01,270 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:01,271 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:01,309 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:01,710 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:01,785 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:45:01,785 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:01,797 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:45:02,497 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:02,503 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:02,503 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:45:02,736 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:02,736 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-11-26 04:45:02,753 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:02,762 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:04,912 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:04,927 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:04,937 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-11-26 04:45:05,897 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:05,913 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:05,914 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:45:06,560 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:06,565 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:06,565 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:08,149 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:08,151 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-11-26 04:45:08,152 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-11-26 04:45:08,152 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-11-26 04:45:08,222 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-11-26 04:45:08,223 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-11-26 04:45:08,224 | app.py:61 | Opened (insecure) gRPC connection
Segmentation fault
[2029   66 2177 ... 1023 2077 2335]
create data 0
[ 539   89  492 ... 1013 1896 2368]
create data 1
[2144  635  319 ... 2247 2442 2118]
create data 2
[1676  634 2335 ... 1233 1709  667]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.8_kmeans -k > ./logs_e1/20_4_attack_0.8_kmeans/client_19_fault_3.log
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,496 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 05:03:59,497 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-11-26 05:03:59,497 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-11-26 05:03:59,498 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-11-26 05:03:59,498 | app.py:72 | Disconnect and shut down
Traceback (most recent call last):
  File "/home/flresearchksu/federated-learning-DIA/cloud/cifar/main.py", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/flresearchksu/federated-learning-DIA/cloud/cifar/main.py", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/flresearchksu/federated-learning-DIA/cloud/cifar/main.py", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/flresearchksu/federated-learning-DIA/cloud/cifar/main.py", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
2021-12-10 02:43:36.567700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:43:36.579792: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[ 369  514 1477   48 1816  348  610  699 1897 2258  178  317 1491 1861
  403 1333 2365 2058 1822 2406   21 1898  476  296 1982 1559 1934 2474
 2000 1627  808 2057 2019  945 2134   75  709 1802  399 2100 1873 1201
 1034  153 2323 2212  587 1182    0 1410 1548  824 1716  995   41  353
  616 1952  629  986 1719 1281 2440  395 1270 2468 2173 2209  550 2278
 1011 1905 2018  753  811 1033   44  407 1821  905  711  472  482 2028
  609 2226  415 1450 1349 2063   32  678  982  427  260  249 1697 1045
 2470 1204 2499 1340  118  586 1583 1318 1118 1684 1723  770 1808 2354
  698 2170 1296 1440  115 2308  452 1605 1146  176  680  502 1072 1258
 1745  675 2349  512 1695 1612 2289  114  129  650   73 1037  750 1286
 1000 1891 1948  203 1634 1493 2220 1674 2351  884 1591 1337  920 1708
  365 2254 1466  133  520  858 2383  277   71   68   97 1641 1411 1487
  185 2434 1483  604   31 2367   47 1436  245  896  537  371 1382 2122
  463 2081  727    9  566  376  384 2132 2271  607   14 1482  991 2223
  947 1196 1628 1877  669 1260  590  193  210 1457 2375 1799 1424  475
 1933  380 2330  611 1066  112  836 1208  834 1322 1263  911  704 2240
 2072 2424 1377  643  559 1834   66   93  230  300  723  976 1752  518
 1987 1407 2327 1312 1305 2397 1264  958 1101 2030 1903 2465 2300 1112
  496 1788  802  106 1151  168 1769 1831 1481 1586 1553 1863 1943 2091
  238 2272  292 2263 2130  363 1849 1463 1726 1479  234 1143 1295  425
 1770 2194 1992  157  972  144  736 1073  362 1049  817 1923 1677 1624
 2027  993   65 1621 1206 2090 2422  303 2137   70 1480  746  215  119
  794 1020  445 1714  745 1874 1472 1017 2230  201 1869  174  499 2454
  505  393 2401  259 1245 1680  632 1847 1654  581 1513 1558  521 1740
 1561 1839  641 2391 2337  103  889 1301  312 1057 1096 1214 1426 1261
 1220 1435 2044 1669 1108 1239  311  978 1389 1535 1475 2317  603  190
 2114 1324 2332  946  197   35 2257  298 1921  987 1444 2269 2429 1242
 1885 1585 1938  964 2162 1288 1431  689 1053 1325 1383 2483  912  522
  200 1575  628 2293  825 1327 1931  287 1019 1177  843 1635 1071  681
  877  211 2035  712 1144  443  726 2498  638  491 2248 1343 2014 1039
  903  280 1616 1359 1540 1176  795 2094  250  640 1844   16 1273 2333
 1503 1331 2485 1851 1120  932 2362 2218  914  368 1505 1819 1005 1963
  170  396 2446   57 2075  717 1836 2436  926 2135 1062  677  901  113
  832 1867 2159  130 1522 2037  527 1347  907  716  573 1148 2043 1533
   62 2451 1083 1809  671 1153  788  973 1443 2133  851 1511   69 1703
  729 1978 1402 1979 1568 1842 1362  725 1381  842 2080  783 1516 1027
  866 2298 1767 2160 1598 1485  146 2493  344 1526  702  915 2175 2373
 1253 1679 1497 1927  672 1676 2140  918 1478 1360 2340 2154  414 1588
  775   77 1688 1297  208  966 1777 1782 1751  881 2430 1275 1710 1870
 1515 1154  155 2239  801  409   64  924 1267  468 1652 1051  416 2104
 2277 2011  790 1950 1429 1940 2106 1823 1040 1470 1689 1246 2074  720
 1845  205  432 1290 1078 1131 2169  301 2235  696 2084 1417 2067  381
 2197  752  487  818 1433 1197  780 1696 2384 1420 1369  467 2111 1043
 1876 1937 1224 1385 1928  497 1366  390  789  812 1302 1962  605 1277
 1890  657 1746 2185  394 2494 2371  969 1399 1150  191 1446 1364 2103
 1145 1543 1655 2445  897 2476 2228 1657  538 1893 2428 2335  623  145
 1904  606 2128 1636 1334 1563 1607 1820    2  182 1113   13  645 1892
 2208 1986 2409 1442 1794  813  156  392 2296 2119  937 2279 1082 2005
 1494  244  361 1878 1984 1227  320 1941 2273 1109  539   12 1136 2443
  241  807 1025 2395 2344 1748 1001  481 1014 2480 1580  213 1538 1271
  479 1512 1387 2165   50 1278 1103 1728 1629  941  493  782  869  108
 1537 2107 1355  772 1547 1614 1376  507  744  263  454 2387 1111   81
 1024  222 2487 1780 2464  175  963 2118  967 1026  387 1476  110  721
  576 1175 1759  735  194 2237  181  343]
create data 0
[  84   16 2095 1619  226 1685 2201  175 2425  583   80  373  194 1525
  177  672  907 2419  737   82   19 2398 1854 1954 1035 1380 2018 1082
 2027 1990 1567 1175 1516 2472  618  552 2474 1466  639 2342 1674 1435
  963 1412    2 1659  403 1953 1271  104 2113  811 2015 2047 2054  378
 1453  588    3  450  677  539   17  695  817 1994  419  705 1006 1864
 1048 1292  731 1583  670 1256 1232  824 1299 1336 1566 1378 2365  999
  570  559 2179 1337  142 1183 1945  161 1062  401  408 1664 1695   54
 1789 1408  844  429  661  404 1448  330  217 1419 1993 1074 1542 1965
 1729  961  557  745  101  120   83  595 2322  839 1640 2416 1846 1942
 1540 1691  607 2041 1595 2447 1961  822 1801 1106 1554  267 2106 1736
 1192 1429 1931  687 1670  153  425 1552  386 2252 1370 2186  151 1587
 2101 1592 1638 1480 1830 2210 1105 1361  279 1331  640 2121 1392 2133
 1777 1148   60 2024  861  387 1550  876 2232 1582 1537 1452   49  305
 1168  422  627 2213 1836  523 1017 1057 1376 1679  827 1665 1391  129
 1865  253 1713  825 1868 2086  231  888 1822 1950 2142  862 1910  647
 1307  821    0 1042 2263 1519 1842  289 2077  995  400  968  796 1529
 1978 1860 2479 2224 1896  212 2072 2297 2031 2311 2293 2114  704 1295
  426   21  910  602  742 1538  311  262 2194  486 1312  370 1233  500
  561 2218   87 1934 2458 2383 1379  947  173 1826 1447  214  392 1935
  365 2060 1007 1026    6  749 1892  472  923 1158  597 2335  715 2462
 2421 1014 2204  694  339  167  220 1811 2484  416 2013 1456 1510  954
 1127  344 1979 1359 1720  785 1787 1840  692  447 1352  543 2173 1041
 2290  874 2463  860  575  762  430 1021  831 2262 2285 2192  810 2042
  884  445  567  838  853 2493 1015  865 1957  752 1309 1631 2280  920
 2350 1556 1657 1547 1778 1140  969 2286   76 2125 1586  917 2283 1194
  265  284 1259 1305 1212  633 1036 1469 1581  577 1003  157 1454  348
 2363 1958  814 2145  283  989 1397   14  270 1150  550 1249 1589 1090
 2411 2104  712 1968 1641 1484 1368 1580  984  172 2381 1534 2309 1754
 1724  321 2457  719  288 1849  434  669 1088   59 1471 1381 2409  921
 1219 1562 2230  690  362 1147 1924 1463 2382 2068  528  650 1969 1223
 1804  903  481 2330 1374 2116 1880 1690 1692  578  847 1335  759 2229
  638 1430  616   31 1179 1661 1308  918 1967 2137 1034 1101 1218  585
 1163  509 1231  832 1411  560  651 1737  326  751 1877   52 1051 2073
 1005  781 1437 2083 1718 1949 2160   46 1812 2207 2249 1362  516 1508
 2023 2495 1904 1806  431  521  994  165 2267   64  526  117  126 1089
  795  346  308 2233 2074  276  462  532  382 1301 1372   43  464  236
 2261 2209 1622  379 1113 1722 1108  411 2090 2066  342 1901  471 1276
  219  668  269  756 1913 2215    1  355  324  866 1988 2098 1165 1110
 1383  193 1884  830  900 1907  623  852 2294 2112 1405 1472  620 1751
  596  787  553 1599 1063 1321  973 1356  703  706  912 2402  619  800
 2251  599 2241  981 1022 1908 1186 2140  376 1700 1258  938 1288 2053
  656 1505 1551  331 2089  332 1487 1485 2055 1667 2043 1579 1388  879
  111 2376 1030  178  549 2148  547  190  635 2008  819 2438 1395 2454
 1591 1867  858  769 1744  970   73 2332  201 1013  246 1320  491  364
 2452  295 2466 1078 1792 1229 1181 1882 1418 2127  224 1093 1597   48
 1012 1196  247 1053 1647 1310 1038 2191  777 1649  592  389  986 1959
 1135  929 1449 1698  428 1159 1963 2246  338 1699 1104  312 1573 1779
 2075  313 2355 2185  962 1490  405  941 2265  946  345 1016 1808  123
  322  207  586 2034 1721  990  483 1446 2028 1710  959  494  352  673
 2314  350 1858  815 1323 1717 1775 1835 1114  436  982 2050  169 1798
 1291 1440  399 2340  686 2473 1895  542  696  195  906  452  485 2169
 1085 2005 1809  937  697  730 1325 1521 2257 1560  974  846  336 1142
 2216 1009 1422 1601 2370   71 1064 1222 1747  803  545  208 1598 1750
 2327 2284 1939  538 2139  833   97 2208]
create data 1
[ 729  420  353 1820   54 1874  661 1832 1559 1711  580 1971  524 1836
 1617  766 2030 1051 1928 1422 1188 1377 1143 1961  757 1845  907 2027
  777  557 1907 1509 1994 1786   41  551  687 1299   70  618 2139 1792
 1999 2123 2450  963  633  286  224 2453 1119  447 1216  786 1622 1307
 1738 2080  726 1305  630  677 1484  256 2020 1001  666  966  898   62
 1747 1251  995  464  137 2250  340 1063  110 1499 1190 1760 1180 2146
 2338  434   79   64  395 1457  731  932  238  936   44  147 1303  967
  946 1868  624 2408 2223  338 2064 1193 2321  530  506 2161 1048   18
  388 1219  563  458 1562  935 1764 2354 2393  244  755  545 1526 1956
 1466  448 1200 2201  207 1015  208 2413 1603  390  993 2127 1972 1885
 2470 1324 2129  954  349  116 1607   39  297  788 2103  918 1158  541
 2299 2090  930 2043 2471  220  711 1524  521  791   65 1897 1881 1177
 1567  873 1808  603 1899 1310 2406   81 1951 1419  644 1317 1424 2287
  518 1442 2051 1472  307 1714  375 1717 2189 1111   85 1578 1722 2266
 1304  172  768 2073 2366  985  497  769 2001 1565   56 2412  700 2390
 1488  855 1448 2422 1757  983 1967 2409  669 2355 2397 1945   25 1166
 1285  175 1785 1914 1721 1901 1229 1037 1802  213   95   34 2401   11
   84  556  514 1527 2101  886 1224 1060  758 2475  452  113 2462   42
 1503 1779 1818 1094 1392  477 2145  549 2060  107 1992 1566 1813  802
 1606  237  887  298 2078  969  288 2360 2392  868 2202 1329 1602 1355
  512  315 1877  629 2265 1772 1099 1570  915 1131 2296 2364 1384 1361
 1495 2174 1160 2382 1287 1859  760  771 2013  965 1927   90 1690  911
 1034 1184  912 1816 2490 2477 2289 1130  746  127 1990   75 2308  380
 1115 1241 1434 1508 1089 1795 1689 1325  847  456 1932  562 1093 1106
  529  653  366  254 2015 1801  122  816 1809 1036  430 2210 1450 1055
 1314  191  453 1146 2100  719 1667 1378 1035 1458  733  564 2388  210
  408 1601 2245  834  641 2479 1066 1959  639 1734  785 2222 2110 2278
 1043 1693  843  674 1205 2427 1185 1837 1847  977 2384  587  355 1316
  879  991  840  139 1839 1587 2353  576 1643  140 1893 1982  891   60
  306  701 1671   31 1122  832 1848 2444 1245  871 2135 1178 1240 1784
 1220 1429 1461 1370 1531 1426 1490 1937  805  623 1345 2173 2181 1074
 2316  119  202 1064  984 2039  752  696 1630  481 1350 1911 2187   58
 1936 2067  406 1054 2358   93  317 2194  544  385 2144  398 1710 1483
  283 1591 1493 1026 1686  974 1723 1123 2178 2083 1506 2136  500 1263
 1984  142 1687  490  505   51  488 1243   32  393  634  578  123   37
  739 1746  994 1198  601 1172 2229  276  525  679  344   10 1794 1016
  902  216 2331 2455 1611 1129 2216 2053  169 1728 1402 2344 2049  211
 1444 1154 2077 1414  560  357 1777 2451 2056  528 1227  621 2203  323
  457 1775  713  612 1088 2224 1541 2079  404  725 2121 1739 1439 1167
 1105 2154 2234  159 1573 1268  926  676  976 1388  170 1109 1988  339
  442  103 1558 2499 1438  990 1095 2155 1805  278 2428  198 2054 2318
 2339 1489 2152  263  658 1427 1234 1012 1892 1121  672 1663  255 2153
   76 1743 1765 2476 1339 1045  343  304 2138 1929 2271 2236  690 2312
   16 2259 1582  499  187 1737 1153  138 1608  948 2386 2281 2063  614
  818  508 1418   43 2141 1157 1076   36 1199 2398 1548 2340  632 2071
  104  959  218 1884 2163  680  346 2460  773 2378 1409  272 1564  174
  531 2341  180  136 2058   29 1346 1226 2377  215 1943 2464  888  934
   94  330 1071 1025  387  167 1869  951 2310  183 2082 2267 2447 1082
 1694  358 1416 1593 1492  826  412 1237 1087  784 2251  129 2199  698
  645 2351  853  947  837 2167 1062  980 1022  320 1389 1926 1379 1068
 1383  952 1397 1511 1436 2075  914  992 1675  822  181  449  118 1543
 2165 1070 2089 1649 1713  271  376 2087 1581 2423 1338 2323  780  483
  345 1631  193 1337  419  441  941  859 1135 2350 1029  735  931  474
  279 1447    5 1013 2055 2282  268 2241]2021-12-10 02:44:03.244323: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.244375: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.279541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.279589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.291651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.291699: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.316949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.317001: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.319408: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.319450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.340832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.340878: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.366630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.366679: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.368360: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.368399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.384882: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.384929: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.452016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.452066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.453196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.453241: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.460464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.460506: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.463227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.463263: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.469321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.469371: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.471728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.471763: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.479273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.479319: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.565622: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.565668: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.568502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.568540: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.599465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.599526: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:03.711423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 02:44:03.711470: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 02:44:08.189506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.189559: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.189584: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.189907: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.255704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.255757: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.255784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.256050: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.343849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.343908: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.343937: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.344232: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.359382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.359436: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.359461: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.359742: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.389161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.389217: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.389247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.389525: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.397695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.397751: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.397778: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.398048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.409426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.409473: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.409497: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.409784: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.447649: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.447698: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.447724: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.448000: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.455489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.455542: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.455578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.455842: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.469244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.469299: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.469324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.469600: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.485340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.485393: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.485420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.485697: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.503460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.503517: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.503545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.503825: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.533405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.533457: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.533484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.533761: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.542126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.542180: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.542207: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.542477: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.553405: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.553460: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.553485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.553760: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.576049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.576102: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.576129: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.576396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.681933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.681984: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.682012: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.682275: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.753864: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.753923: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.753952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.754226: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.773499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.773548: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.773574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.773835: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 02:44:08.875667: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 02:44:08.875721: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 02:44:08.875746: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 02:44:08.876025: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flower 2021-12-10 02:44:29,399 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:44:29,400 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:44:29,478 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:44:31,770 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:44:31,778 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:44:31,822 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:45:56,110 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:45:56,126 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:45:56,203 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:45:58,032 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:45:58,032 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:45:58,066 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:45:58,206 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:45:58,233 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 02:45:58,355 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:45:58,356 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:45:59,255 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:45:59,255 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:45:59,256 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:05,658 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:05,659 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 02:46:05,726 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:05,847 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:06,414 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:06,425 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:06,510 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-12-10 02:46:09,021 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:09,035 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:09,077 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:09,867 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:09,895 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:09,896 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 02:46:09,952 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:09,952 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:10,106 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:10,631 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:10,631 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:10,654 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:10,980 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:10,981 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 02:46:10,981 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:10,987 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 02:46:11,561 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:11,561 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 02:46:11,562 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:11,563 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 02:46:12,903 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:12,916 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:12,950 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:15,059 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:15,060 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:15,129 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:15,520 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:15,523 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 02:46:15,527 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:15,608 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 02:46:15,808 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:15,808 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:15,808 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:16,066 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 02:46:16,080 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 02:46:16,080 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 02:46:16,823 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 02:46:16,833 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 02:46:16,843 | app.py:61 | Opened (insecure) gRPC connection
2021-12-10 03:40:39.469888: F tensorflow/core/platform/default/env.cc:73] Check failed: ret == 0 (11 vs. 0)Thread tf_data_private_threadpool creation via pthread_create() failed.
Aborted

create data 2
[1044 1482  768  389 1353 1520 1416  172  527  685 1529 1368 2206  361
 1991 1882 2207  207 2035 1060  719 1740 2413  218  861  395 1261 1858
 2406  210  192   27  255  679 1177 1419 1979 1942  564  860  249 1843
 2032 1545  466 1675 2310 1784 1088  191 1569 1665 2081  292  406 2389
 1298 1579 1449 1516  875 1205 1435 1648  245 1922 1326  381  421  555
  430 2289 2313 1246  185 1782 1517 1707 2361 1872  722 1752  297 2017
 1972  469  523 2442  947  989 1508 2364 1457 2376 1464  701 1965 1587
 1428 1074  939 1209 1963  967 1443 2348 2267  363  885  119 2175 1165
  951 1670 2248  842 1966  162 1550 1484 2033  985 1331 1745  444 2201
 1346 1812 2184 2460  206 2359  397 1374  597 2322 2082  933  607 2041
  385 1805 2057 1319 1023  928 1302 1780  854 1774  694 1248 1886  808
  752  335 2282 1400 1741 1094  512  610  322 1906 1514  145 1105 2193
 1652  667  108 2141  992  872 2272 2350 2086 2237 1441 1807  772 1100
 2208 2342 1960  402  520  889 2472  629  471 1166  593  440   22  713
  562 1715 1939 2457  793 1689  486 1932 1363 1475 2492  620 1336  261
 1448 1096 1737 2402 1143  868 1417  789   86 1854 1976 1926  496 2133
 1796 1358 2408 1224  643 1277 2075 1290  404  303 2438 1134 1280   61
  545  815 1609  665  124 2209 1392 1034 1235 1247  468 1330 1340 2128
  113 1137 1497 1241 2073 1498 1196 1769 1900  982 1039  168  553  473
 2353  232  683 2363  984 1511 2292  950 1925  180  745 1698 1029 1018
  907  174  201 2012 2328  639 2034 2220 1144  674 1686  499  130 2284
 1725 1212 1584  695   62  355 2462 2213   65  407 2318 2061 1098  771
 1551 2196  987   14 1027  658 2455 1597 1561 2488  858 2306 1058  107
   39  120  175 1071  813 1681 1958  916  115 1055 1990 1467 2194  909
 1422 2446 1600 2095  366 1763  420 1890  483 2493 2434 2067 1891 1073
 2422 2021  530  507  307 2154  156 1393 1697  373 1492 1772 1911 2090
   16 1605 2058 2431  213  710 1295  571 1301 1615 1140 1628 2469 1720
  934 2372 1005 1964 1463   59 1149 2132 1884  463 2297 1591 1699 1744
  567  923  461  379 1000   88  979 2169  457 1080 1929 2031 1797  231
 1721  941 1905 1381 1736  769 1324 1656 2016 2181  929 1186 2069  716
 2043 2319 1210  993  794  757 1607 1909 1999 1775  150  958  686 2104
  773  179   85  171   87  660 2468 1294  383 2252 1840 2443  625 1931
 2251 1297  915 1748  310 1318  280 1397  825 2239  505 1167 2436 1021
 1870  491 2048  495 1536 1259  780 2273 1124  707 2191 1496 1645 1620
 1549   19  975 1269 1278  823 1684  153  568 2088 2123   41 1193 2377
  417  350  732 1518  445  611  788  447 1198 2115 2178  558 1873 1273
  578 1653  493 2146 1373  973 2250 1231 2222 1226  696  278 1659 1612
 2249 1327 1342 2337  998 1201 2244 2130  954 2026  535 2144  730  828
 1418 1755 1596 1282 1097  267  920 1468 2271  239 2224  547  983  263
 1378 1595 1710  723 2344 2439  774  533  743 1638 2161  869  818  196
 1384 2499 2471 1283 2429 1182  351 1501 2179 2263   66  850  926  548
  269  735   51  377 1809  817  252 1842  988 1655 2317  591  741  632
 1469 2290  882 1408  216 1795  870 2366 1503 1598 2343 1367  244 1004
  281 1404 2120   46 1588  546 1237  277  962 1276 2174 2393  997 1092
 1878 2481   23 2411  256 1701 1676 2098 1776  193 2093 1936  382  797
  811  347  690 2187 1803  786 2113  266  131  197  149 1190 2070 2380
 1333  897 2148 1387 1456 1554 1954 1485  427  598 1667  100 1486 2243
  368 1270 1206  616  663 2089 1896 1491 1705 1308 1125 1458 1048  380
 1172    5  390 2231 1855 2045 1101 1427   57 2437 1199  293  619 2338
 1874 1347 1538  809  554  560  721  148 2491 1221 1245  657 1146 2214
 2352 1310 1759  668 1856 1863 2079 1802 1398  580 1959 1746  203  711
 2036 1401 1509   67 1949 2094 1547 1160  147 1903  125  956  820 1618
  467 1086 1126 1488  409   10  105 2085  734 1445 1099   89  286  313
 1334 1362 1132  878  224 1038 2308  566]
create data 3
create data 4
create data 5
create data 6
create data 7
create data 8
create data 9
create data 10
create data 11
create data 12
create data 13
create data 14
create data 15
create data 16
create data 17
create data 18
create data 19
python client.py -c 0 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_0_fault_3.log & python client.py -c 1 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_1_fault_3.log & python client.py -c 2 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_2_fault_3.log & python client.py -c 3 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_3_fault_3.log & python client.py -c 4 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_4_fault_3.log & python client.py -c 5 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_5_fault_3.log & python client.py -c 6 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_6_fault_3.log & python client.py -c 7 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_7_fault_3.log & python client.py -c 8 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_8_fault_3.log & python client.py -c 9 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_9_fault_3.log & python client.py -c 10 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_10_fault_3.log & python client.py -c 11 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_11_fault_3.log & python client.py -c 12 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_12_fault_3.log & python client.py -c 13 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_13_fault_3.log & python client.py -c 14 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_14_fault_3.log & python client.py -c 15 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_15_fault_3.log & python client.py -c 16 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_16_fault_3.log & python client.py -c 17 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_17_fault_3.log & python client.py -c 18 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_18_fault_3.log & python client.py -c 19 -f 3 -m cnn -e local -n 20_4_attack_0.3_kmeans -k > ./logs_f3e30/20_4_attack_0.3_kmeans/client_19_fault_3.log
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,337 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,338 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,338 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
DEBUG flower 2021-12-10 04:27:23,338 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,338 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 04:27:23,338 | connection.py:68 | Insecure gRPC channel closed
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
INFO flower 2021-12-10 04:27:23,340 | app.py:72 | Disconnect and shut down
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-13-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-6-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-4-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-14-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-2-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-17-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-7-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-3-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-18-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-1-fault-3.pkl'
Traceback (most recent call last):
  File "client.py", line 148, in <module>
    with open(f'./logs/{exp_name}/history-{client_index}-fault-{fault_index}.pkl', 'wb') as f:
FileNotFoundError: [Errno 2] No such file or directory: './logs/20_4_attack_0.3_kmeans/history-9-fault-3.pkl'
2021-12-10 16:05:24.594601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:24.594647: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[2092 2240  290  163 2388 1047 1439  474  333 2211 1648 2395  402  638
 1683 1095 1391 1349 1984 1302 1366  814  843  776 1384 1476   82  371
  964 1459  188 1785  516 1932  584 1654 1159 1158  744  539 1874  865
  351  209 2433  968 1034 2068 1350  855  790 1464  331  441 1018 1088
 1233  396  424 1603 1432 2452 2424  391 1164 1861 1000 2208 2175   93
 1411  973 2481  125  213 1087 1882 1957 2039 1813  383  201 2425  294
 1850  519  477 1154  536 2074 1477 2224 2430 1458  215   75  413 2003
  861 1388  925  228 2053 1965 2332  525 1125 1368 2010  848 2005 1796
  255 2218  271 1090  109  449 2177  312 1889 1842 1414 2178 1941  465
 2326 1218 1592 1354 2444  923 1003 1783 1248  577 1733  430  674 1954
 2249  182 1786 2369 1722    7 2070  211  384  862  713 1584  730 1135
 1403  666 1505  388 1806 1409 1950 2056 1551 1789 1479  354 1627 2250
  560 1020 1189 1200   26 2298  407   45 1132  189 1076 2160 1939  739
 1400 1240 2167 1142 1737 1376  195  126 2280 1316 2009 1862 1512 1990
  789 2329 1096 1709  277  149  157  233  279 1777 2461 1879 2485  366
 1960  329 1222  787 1303 2233  635  300  955 1640  250  284 2380 1097
   23  952  411  853  350 1825 2113 2210  785  852 2350 1949  579 1963
  427 1497 2102  875 2108 1161 1048 1066  977 2489 2036   61 2075 1425
  540 1582 1211  369 1008  874 1358 1116 1234 2080  274  967 1856 2379
 2364 1923  488 2473 1945 1793  665 1487 2004   83 1390 1740  315  912
 2045  896  602  530  727 1873 1577 1983 1631 1738 1284  495 1574  153
 1485  410  328  192 1721 2159  168  443 1001 1406   27   16  257  860
  500 1922  306    2 2415 1065   49 1296  617 1797   60 2138 1650  656
 2050 1351  418  717  876 2161 2031  137  472  798 1570  196  645 2225
  872 1315 2144   37 1186 1340 1834 1134 1723  359 2420 1660 1768  820
 2323 1612 2051 1919   86 1333 1798  167 1866  501  982  770  225  282
   48 1751 2460 1974 1930 1901 1146 1422  562 1600 1373  278 1011 2370
 1772 2205  687  475  380 1704  224  793  101 1480 2487 1365 1510  538
  981 2156 2382 1898 1710  678  404  115 2315 1143 2013 1693 1084 2405
  483 2282 1601 1996 2362  945 1840 1643 2299  690 2196 1050 1255 2187
  631  740   96 1030  958  641 1407 1940 1389   57  971 1651 1111 2259
   24 2319 1236 2289 1219 1848  634  616  141  550 1838   13  421 2391
 1849  780 1252   88   63 1433 2385  950 1759 1979 1581  779 1106 1221
 1457  933 2347  270 2314 1435 1446  114 1868  611 1792 1310 1644 2030
   66  693 1013 2169  613  110 1677  802  100 1395 1647 1944 2110 1616
 2121 1489 1881  777    8 2297  208 2449   89 1921  112  318 2099 1416
 1720  140 1845  463 2476 1770 1074 1162 1621 2033   20 1942 2073 2462
 2015  299  514  700  554 1955  783  558 1666 2478 2437 1694 1522 1903
   92 2048 1779 1769 1150 2404 2389 1370 1341  457 2231 1870  850 2495
  179 1348  607 2403 1637 2089  573  754 2189 2137  440 1706  807  824
  704 2293 1288 1299 1329  992  247 1021 1305 1684 1292  287 1264 2223
  801  117 1892  668   38 1658  810 1397  799  885 1309  119 1145 2333
 1642 2157 2059 1052  836 1402  389 1494 1715  453  297  819 1749 1511
 1093 2052  438  922  302 1083 2041  400 1746 1591 1794 1369 2324 2451
 1060 1700  258 1999 2106 1871 1725  924 2374 1461  387 1035 1911 1791
  526 2290  600   97 2066 1844   36  381   12  791  178 2111 1877 1127
  120 1338  340  837 1520 1531  343 1924 1269 1336  996 2441 1902 1726
 2114 1931  644  671  210 2181  337  409 1560  176 1952 1909 1383  437
 1578 1022 2145  460 1279 2469 1401 1534 2214  782 1147  965 1623  124
 1589 1787  544 2486 2359 1972  352 1342 1069 2027 1332   67 2377  842
  547 1046 1361 1081 1516   42  821  291  591 1636 2244 1006 1555 1056
   25 1100 1205 2328 1450 2291 2116  667   68 1661 1496 1729 1788  903
 2122 1166 2493   62  831 2464  980  177 1696 1362 1072  473 2408  697
 1448 2354  326 1920 1622 1499  452 1455]
create data 0
[1328  526 2264 1794  669 2229 1844 1367 2475 1751 1757 1609 1808 2043
  514  602 1545 2015  755  430  561 1177  605  652 1750  279 1774 1049
  642 2144 1139  396  843 1235  851 2468 1023   57 2491 2407  215  276
 1486 1790 2137 2126 1146 1110  314  808  219  694 1654 1080 2067   46
  948 1721 1939 1843  757 1156   41 1931  877   91  236 2034 1470 1634
  299 1692 1662 1943 2337 1905  323  889  328 1004 1092  132 2461 1823
 1675  135 2068 1420  785 1670 1593 2142  238  760 1009  966 2285 1642
 2392 2430 1186    5 1141 1988  875  846 1491 2297 2102 1037 1027 1789
 2228 1999 1672 2040 1389 2245  715 2047 1150 1460 1465  497  824 2202
  216   39 2134 2476 1429 1119 2351  775  896 2106 2111 1911  311 2368
 1604 1579  867  287 1255  407 1775  916 2014 1811  232  676 1942  419
 1395 1908 1984 2458 1275 1241 1468 1802 2485  437  589 1265 2248  431
  672  406 2247   65  527 1640 1433 2284 2093 1091  503 1863  326 1171
 1301 2419  362 1011 1077 1015 1122 1126 2249  575  531  480 1463 1555
  240 1341 2060  898 1952  492 1333  518 1683  591  769 2187 1777 2465
  412 2062 1671 1738  686 1949  665 1985  133 2424 1298 1885   58 1197
 1051 1904  777  393  886  307 1875  585  242  152  899 1901 2141 2074
 2054 1245 2168  707  489 1831 1828 1477 1994  998 1446  657 1563 1633
  161  312   26  169  194 1549  338 2131  128  704  696  586 2394  708
 2252 1044  815 1829  388 1652 2071  414 1710 1225 1163  535  398  878
  404 2052  530 2315 1615 2029  150   82 1778 2140  223  621 2479 2426
 1331 2281 1849 1795 2039  684   40 2434  897 1561 1478 1300 2156   89
  334 1735 1347  483 1924  568 2048 1356  212  327 1957  199 2438  495
 1094 1830 2408 1335  488 1684  188  453   84 2129  464 2207 2185  556
  913 2339  903 1431   31 1539 1576 1244   28  871  615 2215 1326 2110
 1910 2231  658 1033 2176 1653 1162 1232 1841 2244  463  509 2371 1915
  614 2292 1765 1329  266 1476   88 1529  691  424 1649 1746  644 1450
  892 1801 1419 1200   75   76 1717  905  191  829  941 2405 1980  533
 1123 1782 2183 1669 1251  193 1103 1393   38  748  786 1203  411 2444
 2214 1847 1644 1881  567  563 1075 2380   37  473  289 2388  805 2211
 1246 1825 2377  732 1535 1526 1098 1032 1499 1022 1622  834 1423 2437
 2270 1906 1512  859 1732 1432 1626  562 1313 1632 1457  196 1567 2094
  881 1880 2381 1355   72 1736  243 1088 2409 1620 1309 1248  316    9
  335 1097  710  934 1936 1992 2448 1434 1042 1629   16 2026  929  890
 2112 2235 1008 2299  286 2041 1768 1511 2328  461  247 2356 1853 1583
 2257 1117  791 2443  377 1034 2469 2135 1892  622 1616 1399 1895 1220
  596    6 1099  104 1006  123 1105 1827 1168 1734  444  662 2319 2143
  507  230 2325 1239  975 1149  784 2158  295  736   71 2005  389  855
  336 2019  481 1557  721  345  321 2378 2326  862  234  555 1711  351
  415 1190 2125  441 2098  493  960 1852 2090  146 2105 1272  919 2499
 2413  770 1887 2287 1459  525 1165 1783  110 1005  459 2159 2164  486
  167 2366  218  278 2109  107  971  927  273 1401 1821 1930 1619 2177
  811 1452 1537  143 1925  517  557 1263 1185 1344  812  181 1869   34
  937 1519 2180  833 1381  121 1437  608 1982 2375 2393  940 1048  423
  103  719 1525  961 2036  594  375 1060  467  752 1500 1312 1002 2414
  800 2266  293  536  939   19  782 2049 1026 1405  914   21  902 1728
 2064  894 1879  532 1057 2449  163  858 1229 1891  640 1700 1483 2030
 1638  926 2362 2275 1040 1927  130  141 1773 1113  348  225  706  257
  827 1350 2361 1193 2232 2303 1870  405 1621 2446 1889 1663  835 1648
 1031  397 1068 1585  978  779  993  711   50 2260  353 1523 1531   12
  432  713  436    4 1455  884 1592 2099 2277 1607 1435  804  177 2350
  422 1489  545  918 1760  134 2290 2008 1690 1380 1897  700 1464 2122
  116  852 1548  990 1474 1175 1357 2467 2258 1403 2497  972  856 2084
  703  724 1124 1261 1921  718  496 1933]
create data 1
[1168 1530 1617  595 1501 1279  932 2014 1596 1838 1048 2380  378  277
 2465  106  309 1141 1234 1562  748  346 1524  292 1238 1452 2190 2181
 1837 2061 1069 1834  853 1568 1646  710 2433 1015  317 1384   36 1952
 2132  685 1786 1021 1446  131  109 1748 1121 2150  206 1219 2362 2285
  740 1790 1947 1146 1226 1153 2468  467  141  256  103 1257 1963   40
  789  555  914  110  193 1728 1986  536  864 2369  682  961 1203 1658
 2365 1323 2294  966 2432 1354 2193  681  972 1523  759 2204  570 1734
  802 2145 1458  461 1283  684 1401 1620  625 1613 1880 2095 1466  439
 2139 1985  675 1533 2226 1576 1874  852  340 2012 1720 1749  458  315
 1240 2238 2477 1251 2474  730 1001 2055  859  181 1182  334 1993  554
  705 1922  412 1171 1166 1105  578 1067 1256 1314 1592 1954  427    5
  693  138  757  905  534 2117 1421 1635 1188 2114 2335 2319 2378  670
  164  323 1408 1065 2304 1674 1755 1832  157  219  297 2002  379 1086
 1762 1894 2091 2228  761 1028  496  935  742 2049 1585 1828  643  232
  275  227  666  524 1972 1375  495  732 1382 2406 1464  752 1423 1760
 1766  221 1778 1244  648 1406 1410 1806 2416 1374 1595  959  987 1696
 1844 1198 1303  208 1522 2324  311  448  957  359 1393 1217 1337  332
 2411 1938  504 2009 1324 1820  871 1070 1185 2258 2072 1371 2383  301
  207  170 2412  532 1469 2407  486 1290 2373 1887 2075  659 2022 1483
 1854 1791  268 1300  928 1332 1782  325 1451 1248 1944 2213  897 1473
 2355  649 2131 2452 1360 1686 1372  978 1519  191 1076  364 1224  491
 2059 1312  161 1896 1117 1138 1321 2486  547 1900 1425 2313 1706  919
  253  392  272 2401  847 2231 2058  410  998  488 2159 2332  562  926
  736  453  988 1726  803  980  223 1007  787 1343 2202 1905 1286   96
  310  122 2283   67  673 2257  818  747 1134 1959 1309 2454 2210 2390
  937 1664  837  213 1438  479  923  568  991 2194  328  136 1225 2278
 2043 1529 2446 1428  355   65 2172 2123 1624  333 1140  171  942 1555
 1571 1934  527 1111 1440 2155  984  342 1016 2421 1673  874  525  121
 1463   68  296 1094 2098  376 1250 1918 1258 1504  782 1979  386 1824
 2487 1548  250   21  632 1655 1939 1602  724 1989 1206 1154 1155 2233
 2260 1839 1405  593  692  704 1671 1552   26  494 1556  940  308  784
 1862  582 1032 2245 1212   99 2084 1964 1299 1767 1689  688  737 1609
 1971  574   47  362 1687 1809  658 2427 1271 1974 1672  348 2033 2248
 1827 1517 1580 1013 2363 2334  411 1228    1 1287  892  443 1062 1542
 2312 1668 1849 1261  282 1789 1669 2180 2164  779 2470 2019 2144 1137
 2044  944 1165  633 2488 2472  746 1429 1875 2211  594 1368  933  300
  361 1130  709 1616 1690 1192 2246  199  753 2297   57  861 2374 2223
  166 1978   31 1825  226  889 1436 1325 1335  421  712  457  731 1255
  687 1759 1308  242 2185 2078  278  116 1493 1052  159  447 2482  561
 1389  711 1071  544   52 1962  130 1618  968 2122  264 2057 1691 1724
  764  503 1381 2182 1281  838 1091 2288  303 2199 1355  350 1297 2008
 2147 1471 1319 1925 1043   23 1090 2163  689 2268 2003 2111 2484 1804
 2221 1200 1485  888 1758 1072 2330 1815 1645 1563  423 1904 2220  371
   89 1813 1394 1322 1047   83 2448 1439 1063 1489 2099 1060 1004  294
 2229 1280 2086 2361 1135 2455 1879 1650 1149 2346 2217  360  372 2403
  876 1780  539  196  514 1474 1220   24  388 2157  943 1559 1316 1108
 1697 1943 1770  575  402  806 1385 1320  117 2010 2062  522 2005  790
  255  100 1729 1798 2225 1110  785 1266  314 2302 1058  382   14  363
  396 1969  895  455  866 1020   44 1089  338 2397 2394 1796 1084 1995
  389 1660  792  284 1956  484  817 1742  492 2206 2173  772 1265 2451
 1284  810  529 2141  642 1632 1913 2461 1162 1277  762 2345 2483 2359
 2306 2370   29 1313 1920 1601 1115  857 1619 2179 1603 1597 1715 2331
 2357  882 1800  354  805 1380 1487  898 1560 1230 2112  667 1659  948
 1243 1491 1329 2241 2035 2209 1057 2107]2021-12-10 16:05:53.003883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.003940: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.255738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.255787: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.259364: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.259406: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.265888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.265932: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.266287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.266312: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.279954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.280005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.321486: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.321538: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.326393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.326435: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.337964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.338013: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.338224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.338258: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.338870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.338898: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.359681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.359731: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.395091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.395140: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.398924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.398929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.398969: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.398979: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.424645: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.424698: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.440131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.440176: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.441565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.441604: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.520802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.520852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:53.554086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-12-10 16:05:53.554140: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-10 16:05:58.129103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.129164: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.129192: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.129525: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.190961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.191017: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.191046: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.191357: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.248261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.248327: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.248351: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.248648: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.250820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.250864: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.250886: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.251247: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.288906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.288958: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.288987: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.289269: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.300601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.300655: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.300680: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.300958: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.314119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.314174: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.314202: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.314573: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.321380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.321428: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.321454: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.321734: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.387231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.387285: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.387313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.387573: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.391472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.391514: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.391539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.391792: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.391992: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.392022: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.392043: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.392330: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.408613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.408673: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.408700: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.408997: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.417479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.417527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.417552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.417813: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.431817: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.431891: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.431919: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.432207: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.471859: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.471914: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.471943: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.472211: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.542928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.542981: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.543006: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.543267: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.553973: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.554031: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.554058: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.554331: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.560139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.560192: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.560217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.560493: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.570344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.570399: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.570426: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.570692: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-10 16:05:58.602865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-12-10 16:05:58.602921: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-10 16:05:58.602948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-1): /proc/driver/nvidia/version does not exist
2021-12-10 16:05:58.603225: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO flower 2021-12-10 16:06:04,663 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,668 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,671 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,690 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,690 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,695 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,702 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,705 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,706 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,707 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,718 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-12-10 16:06:04,719 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,719 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,726 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,727 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,728 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,734 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,741 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,750 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,758 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,759 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,758 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,759 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,759 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,759 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,761 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,766 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,777 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,778 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,784 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,784 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,785 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,790 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,798 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,801 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,801 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,801 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,802 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,802 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-12-10 16:06:04,803 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-12-10 16:06:04,803 | app.py:61 | Opened (insecure) gRPC connection
INFO flower 2021-12-10 16:06:04,804 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,806 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,806 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,806 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,807 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,807 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,807 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,808 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,808 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,808 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,809 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,809 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,812 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,813 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,814 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,814 | connection.py:36 | ChannelConnectivity.IDLE
INFO flower 2021-12-10 16:06:04,815 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,815 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,826 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,827 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,827 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,831 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,832 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,832 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,832 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,832 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,832 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,832 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,834 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,835 | connection.py:36 | ChannelConnectivity.CONNECTING
INFO flower 2021-12-10 16:06:04,835 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 16:06:04,837 | connection.py:36 | ChannelConnectivity.READY
DEBUG flower 2021-12-10 16:06:04,922 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 16:06:04,923 | connection.py:36 | ChannelConnectivity.CONNECTING
DEBUG flower 2021-12-10 16:06:04,923 | connection.py:36 | ChannelConnectivity.READY
INFO flower 2021-12-10 16:06:04,923 | app.py:61 | Opened (insecure) gRPC connection
DEBUG flower 2021-12-10 18:41:04,660 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:41:32,912 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:42:11,021 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:43:00,033 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,326 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,814 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:52:21,326 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:55:33,697 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:54:30,746 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:57:47,333 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 18:59:40,443 | connection.py:36 | ChannelConnectivity.IDLE
DEBUG flower 2021-12-10 19:17:26,935 | connection.py:68 | Insecure gRPC channel closed
DEBUG flower 2021-12-10 19:17:26,935 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1639160949.980939129","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1639161028.345737136","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-12-10 19:22:41,664 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1639161360.394856948","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
DEBUG flower 2021-12-10 19:22:43,461 | connection.py:68 | Insecure gRPC channel closed
Traceback (most recent call last):
  File "client.py", line 143, in <module>
    fl.client.start_numpy_client("localhost:8080", client=CifarClient())
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 115, in start_numpy_client
    grpc_max_message_length=grpc_max_message_length,
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/app.py", line 64, in start_client
    server_message = receive()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/flwr/client/grpc_client/connection.py", line 60, in <lambda>
    receive: Callable[[], ServerMessage] = lambda: next(server_message_iterator)
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 426, in __next__
    return self._next()
  File "/home/flresearchksu/miniconda3/envs/venv/lib/python3.7/site-packages/grpc/_channel.py", line 809, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "keepalive watchdog timeout"
	debug_error_string = "{"created":"@1639160858.622828304","description":"Error received from peer ipv6:[::1]:8080","file":"src/core/lib/surface/call.cc","file_line":1069,"grpc_message":"keepalive watchdog timeout","grpc_status":14}"
>
